2023-03-14 22:58:18,615:INFO:PyCaret Supervised Module
2023-03-14 22:58:18,616:INFO:ML Usecase: classification
2023-03-14 22:58:18,617:INFO:version 2.3.10
2023-03-14 22:58:18,617:INFO:Initializing setup()
2023-03-14 22:58:18,617:INFO:setup(target=label, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree', 'ks': 'KS Statistic Plot'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=42, log_experiment=False, experiment_name=None, experiment_custom_tags=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-03-14 22:58:18,620:INFO:Checking environment
2023-03-14 22:58:18,620:INFO:python_version: 3.8.16
2023-03-14 22:58:18,620:INFO:python_build: ('default', 'Mar  2 2023 03:18:16')
2023-03-14 22:58:18,620:INFO:machine: AMD64
2023-03-14 22:58:18,620:INFO:platform: Windows-10-10.0.19045-SP0
2023-03-14 22:58:18,620:INFO:Memory: svmem(total=17007173632, available=8540745728, percent=49.8, used=8466427904, free=8540745728)
2023-03-14 22:58:18,620:INFO:Physical Core: 6
2023-03-14 22:58:18,620:INFO:Logical Core: 12
2023-03-14 22:58:18,620:INFO:Checking libraries
2023-03-14 22:58:18,621:INFO:pd==1.5.3
2023-03-14 22:58:18,621:INFO:numpy==1.20.3
2023-03-14 22:58:18,621:INFO:sklearn==0.23.2
2023-03-14 22:58:18,621:INFO:lightgbm==3.3.5
2023-03-14 22:58:18,622:WARNING:catboost not found
2023-03-14 22:58:18,623:WARNING:xgboost not found
2023-03-14 22:58:18,623:INFO:mlflow==2.2.1
2023-03-14 22:58:18,624:INFO:Checking Exceptions
2023-03-14 22:58:18,624:INFO:Declaring global variables
2023-03-14 22:58:18,624:INFO:USI: 8e11
2023-03-14 22:58:18,624:INFO:pycaret_globals: {'n_jobs_param', 'master_model_container', 'html_param', 'logging_param', 'log_plots_param', '_ml_usecase', 'fold_groups_param_full', '_all_metrics', 'create_model_container', 'pycaret_globals', 'USI', 'iterative_imputation_iters_param', 'fold_generator', 'transform_target_param', 'imputation_regressor', 'fold_shuffle_param', 'dashboard_logger', 'X_train', 'fold_groups_param', 'y', 'target_param', 'transform_target_method_param', 'experiment__', '_all_models', '_internal_pipeline', 'fix_imbalance_method_param', 'display_container', 'prep_pipe', 'y_test', 'stratify_param', '_available_plots', 'X', 'X_test', 'exp_name_log', 'seed', 'gpu_param', 'data_before_preprocess', '_all_models_internal', 'imputation_classifier', 'fix_imbalance_param', 'y_train', 'fold_param', '_gpu_n_jobs_param'}
2023-03-14 22:58:18,624:INFO:Preparing display monitor
2023-03-14 22:58:18,624:INFO:Preparing display monitor
2023-03-14 22:58:18,637:INFO:Importing libraries
2023-03-14 22:58:18,637:INFO:Copying data for preprocessing
2023-03-14 22:58:18,645:INFO:Declaring preprocessing parameters
2023-03-14 22:58:18,646:INFO:Creating preprocessing pipeline
2023-03-14 22:58:18,663:INFO:Preprocessing pipeline created successfully
2023-03-14 22:58:18,663:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-03-14 22:58:18,664:INFO:Creating global containers
2023-03-14 22:58:18,666:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-03-14 22:58:31,183:WARNING:Couldn't import xgboost.XGBClassifier
2023-03-14 22:58:31,183:WARNING:Couldn't import catboost.CatBoostClassifier
2023-03-14 22:58:31,249:WARNING:Couldn't import xgboost.XGBClassifier
2023-03-14 22:58:31,249:WARNING:Couldn't import catboost.CatBoostClassifier
2023-03-14 22:58:31,250:INFO:Creating grid variables
2023-03-14 22:58:31,263:INFO:create_model_container: 0
2023-03-14 22:58:31,263:INFO:master_model_container: 0
2023-03-14 22:58:31,263:INFO:display_container: 1
2023-03-14 22:58:31,268:INFO:Pipeline(memory=None,
         steps=[('dtypes',
                 DataTypes_Auto_infer(categorical_features=[],
                                      display_types=True, features_todrop=[],
                                      id_columns=[],
                                      ml_usecase='classification',
                                      numerical_features=[], target='label',
                                      time_features=[])),
                ('imputer',
                 Simple_Imputer(categorical_strategy='not_available',
                                fill_value_categorical=None,
                                fill_value_numerical=None,
                                numeric_strate...
                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),
                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),
                ('cluster_all', 'passthrough'),
                ('dummy', Dummify(target='label')),
                ('fix_perfect', Remove_100(target='label')),
                ('clean_names', Clean_Colum_Names()),
                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),
                ('dfs', 'passthrough'), ('pca', 'passthrough')],
         verbose=False)
2023-03-14 22:58:31,268:INFO:setup() succesfully completed......................................
2023-03-14 22:59:04,313:INFO:Initializing compare_models()
2023-03-14 22:59:04,313:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-03-14 22:59:04,314:INFO:Checking exceptions
2023-03-14 22:59:04,315:INFO:Preparing display monitor
2023-03-14 22:59:04,315:INFO:Preparing display monitor
2023-03-14 22:59:04,343:INFO:Initializing Logistic Regression
2023-03-14 22:59:04,343:INFO:Total runtime is 0.0 minutes
2023-03-14 22:59:04,355:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:04,356:INFO:Initializing create_model()
2023-03-14 22:59:04,356:INFO:create_model(estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:04,356:INFO:Checking exceptions
2023-03-14 22:59:04,356:INFO:Importing libraries
2023-03-14 22:59:04,356:INFO:Copying training dataset
2023-03-14 22:59:04,357:INFO:Defining folds
2023-03-14 22:59:04,357:INFO:Declaring metric variables
2023-03-14 22:59:04,365:INFO:Importing untrained model
2023-03-14 22:59:04,376:INFO:Logistic Regression Imported succesfully
2023-03-14 22:59:04,407:INFO:Starting cross validation
2023-03-14 22:59:04,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:12,526:INFO:Calculating mean and std
2023-03-14 22:59:12,529:INFO:Creating metrics dataframe
2023-03-14 22:59:12,542:INFO:Uploading results into container
2023-03-14 22:59:12,543:INFO:Uploading model into container now
2023-03-14 22:59:12,543:INFO:create_model_container: 1
2023-03-14 22:59:12,544:INFO:master_model_container: 1
2023-03-14 22:59:12,544:INFO:display_container: 2
2023-03-14 22:59:12,545:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-14 22:59:12,546:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:12,692:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:12,692:INFO:Creating metrics dataframe
2023-03-14 22:59:12,704:INFO:Initializing K Neighbors Classifier
2023-03-14 22:59:12,704:INFO:Total runtime is 0.1393614927927653 minutes
2023-03-14 22:59:12,712:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:12,713:INFO:Initializing create_model()
2023-03-14 22:59:12,713:INFO:create_model(estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:12,713:INFO:Checking exceptions
2023-03-14 22:59:12,713:INFO:Importing libraries
2023-03-14 22:59:12,713:INFO:Copying training dataset
2023-03-14 22:59:12,714:INFO:Defining folds
2023-03-14 22:59:12,715:INFO:Declaring metric variables
2023-03-14 22:59:12,722:INFO:Importing untrained model
2023-03-14 22:59:12,731:INFO:K Neighbors Classifier Imported succesfully
2023-03-14 22:59:12,751:INFO:Starting cross validation
2023-03-14 22:59:12,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:15,159:INFO:Calculating mean and std
2023-03-14 22:59:15,160:INFO:Creating metrics dataframe
2023-03-14 22:59:15,166:INFO:Uploading results into container
2023-03-14 22:59:15,167:INFO:Uploading model into container now
2023-03-14 22:59:15,167:INFO:create_model_container: 2
2023-03-14 22:59:15,167:INFO:master_model_container: 2
2023-03-14 22:59:15,167:INFO:display_container: 2
2023-03-14 22:59:15,167:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-14 22:59:15,167:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:15,262:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:15,262:INFO:Creating metrics dataframe
2023-03-14 22:59:15,271:INFO:Initializing Naive Bayes
2023-03-14 22:59:15,271:INFO:Total runtime is 0.18214271465937298 minutes
2023-03-14 22:59:15,282:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:15,283:INFO:Initializing create_model()
2023-03-14 22:59:15,283:INFO:create_model(estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:15,283:INFO:Checking exceptions
2023-03-14 22:59:15,284:INFO:Importing libraries
2023-03-14 22:59:15,284:INFO:Copying training dataset
2023-03-14 22:59:15,284:INFO:Defining folds
2023-03-14 22:59:15,285:INFO:Declaring metric variables
2023-03-14 22:59:15,291:INFO:Importing untrained model
2023-03-14 22:59:15,298:INFO:Naive Bayes Imported succesfully
2023-03-14 22:59:15,313:INFO:Starting cross validation
2023-03-14 22:59:15,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:15,352:INFO:Calculating mean and std
2023-03-14 22:59:15,352:INFO:Creating metrics dataframe
2023-03-14 22:59:15,356:INFO:Uploading results into container
2023-03-14 22:59:15,357:INFO:Uploading model into container now
2023-03-14 22:59:15,357:INFO:create_model_container: 3
2023-03-14 22:59:15,357:INFO:master_model_container: 3
2023-03-14 22:59:15,357:INFO:display_container: 2
2023-03-14 22:59:15,357:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-14 22:59:15,358:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:15,439:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:15,439:INFO:Creating metrics dataframe
2023-03-14 22:59:15,449:INFO:Initializing Decision Tree Classifier
2023-03-14 22:59:15,450:INFO:Total runtime is 0.18512483040491742 minutes
2023-03-14 22:59:15,458:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:15,459:INFO:Initializing create_model()
2023-03-14 22:59:15,459:INFO:create_model(estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:15,459:INFO:Checking exceptions
2023-03-14 22:59:15,459:INFO:Importing libraries
2023-03-14 22:59:15,459:INFO:Copying training dataset
2023-03-14 22:59:15,460:INFO:Defining folds
2023-03-14 22:59:15,461:INFO:Declaring metric variables
2023-03-14 22:59:15,468:INFO:Importing untrained model
2023-03-14 22:59:15,476:INFO:Decision Tree Classifier Imported succesfully
2023-03-14 22:59:15,491:INFO:Starting cross validation
2023-03-14 22:59:15,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:15,534:INFO:Calculating mean and std
2023-03-14 22:59:15,535:INFO:Creating metrics dataframe
2023-03-14 22:59:15,538:INFO:Uploading results into container
2023-03-14 22:59:15,538:INFO:Uploading model into container now
2023-03-14 22:59:15,538:INFO:create_model_container: 4
2023-03-14 22:59:15,538:INFO:master_model_container: 4
2023-03-14 22:59:15,538:INFO:display_container: 2
2023-03-14 22:59:15,539:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=42, splitter='best')
2023-03-14 22:59:15,539:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:15,620:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:15,620:INFO:Creating metrics dataframe
2023-03-14 22:59:15,629:INFO:Initializing SVM - Linear Kernel
2023-03-14 22:59:15,630:INFO:Total runtime is 0.18813139200210574 minutes
2023-03-14 22:59:15,638:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:15,638:INFO:Initializing create_model()
2023-03-14 22:59:15,638:INFO:create_model(estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:15,638:INFO:Checking exceptions
2023-03-14 22:59:15,638:INFO:Importing libraries
2023-03-14 22:59:15,638:INFO:Copying training dataset
2023-03-14 22:59:15,639:INFO:Defining folds
2023-03-14 22:59:15,640:INFO:Declaring metric variables
2023-03-14 22:59:15,647:INFO:Importing untrained model
2023-03-14 22:59:15,655:INFO:SVM - Linear Kernel Imported succesfully
2023-03-14 22:59:15,670:INFO:Starting cross validation
2023-03-14 22:59:15,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:15,710:INFO:Calculating mean and std
2023-03-14 22:59:15,710:INFO:Creating metrics dataframe
2023-03-14 22:59:15,716:INFO:Uploading results into container
2023-03-14 22:59:15,716:INFO:Uploading model into container now
2023-03-14 22:59:15,716:INFO:create_model_container: 5
2023-03-14 22:59:15,716:INFO:master_model_container: 5
2023-03-14 22:59:15,716:INFO:display_container: 2
2023-03-14 22:59:15,717:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-14 22:59:15,717:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:15,799:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:15,799:INFO:Creating metrics dataframe
2023-03-14 22:59:15,811:INFO:Initializing Ridge Classifier
2023-03-14 22:59:15,811:INFO:Total runtime is 0.19114440282185874 minutes
2023-03-14 22:59:15,818:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:15,818:INFO:Initializing create_model()
2023-03-14 22:59:15,819:INFO:create_model(estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:15,819:INFO:Checking exceptions
2023-03-14 22:59:15,819:INFO:Importing libraries
2023-03-14 22:59:15,819:INFO:Copying training dataset
2023-03-14 22:59:15,820:INFO:Defining folds
2023-03-14 22:59:15,820:INFO:Declaring metric variables
2023-03-14 22:59:15,827:INFO:Importing untrained model
2023-03-14 22:59:15,834:INFO:Ridge Classifier Imported succesfully
2023-03-14 22:59:15,849:INFO:Starting cross validation
2023-03-14 22:59:15,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:15,882:INFO:Calculating mean and std
2023-03-14 22:59:15,883:INFO:Creating metrics dataframe
2023-03-14 22:59:15,887:INFO:Uploading results into container
2023-03-14 22:59:15,887:INFO:Uploading model into container now
2023-03-14 22:59:15,887:INFO:create_model_container: 6
2023-03-14 22:59:15,887:INFO:master_model_container: 6
2023-03-14 22:59:15,887:INFO:display_container: 2
2023-03-14 22:59:15,888:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize=False, random_state=42, solver='auto',
                tol=0.001)
2023-03-14 22:59:15,888:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:15,981:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:15,982:INFO:Creating metrics dataframe
2023-03-14 22:59:15,994:INFO:Initializing Random Forest Classifier
2023-03-14 22:59:15,994:INFO:Total runtime is 0.1941842834154765 minutes
2023-03-14 22:59:16,003:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:16,004:INFO:Initializing create_model()
2023-03-14 22:59:16,004:INFO:create_model(estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:16,004:INFO:Checking exceptions
2023-03-14 22:59:16,004:INFO:Importing libraries
2023-03-14 22:59:16,005:INFO:Copying training dataset
2023-03-14 22:59:16,006:INFO:Defining folds
2023-03-14 22:59:16,006:INFO:Declaring metric variables
2023-03-14 22:59:16,015:INFO:Importing untrained model
2023-03-14 22:59:16,026:INFO:Random Forest Classifier Imported succesfully
2023-03-14 22:59:16,045:INFO:Starting cross validation
2023-03-14 22:59:16,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:16,801:INFO:Calculating mean and std
2023-03-14 22:59:16,802:INFO:Creating metrics dataframe
2023-03-14 22:59:16,806:INFO:Uploading results into container
2023-03-14 22:59:16,806:INFO:Uploading model into container now
2023-03-14 22:59:16,807:INFO:create_model_container: 7
2023-03-14 22:59:16,807:INFO:master_model_container: 7
2023-03-14 22:59:16,807:INFO:display_container: 2
2023-03-14 22:59:16,807:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2023-03-14 22:59:16,807:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:16,892:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:16,892:INFO:Creating metrics dataframe
2023-03-14 22:59:16,901:INFO:Initializing Quadratic Discriminant Analysis
2023-03-14 22:59:16,901:INFO:Total runtime is 0.20930206378300986 minutes
2023-03-14 22:59:16,912:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:16,912:INFO:Initializing create_model()
2023-03-14 22:59:16,913:INFO:create_model(estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:16,913:INFO:Checking exceptions
2023-03-14 22:59:16,913:INFO:Importing libraries
2023-03-14 22:59:16,913:INFO:Copying training dataset
2023-03-14 22:59:16,914:INFO:Defining folds
2023-03-14 22:59:16,914:INFO:Declaring metric variables
2023-03-14 22:59:16,922:INFO:Importing untrained model
2023-03-14 22:59:16,929:INFO:Quadratic Discriminant Analysis Imported succesfully
2023-03-14 22:59:16,944:INFO:Starting cross validation
2023-03-14 22:59:16,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:16,998:INFO:Calculating mean and std
2023-03-14 22:59:16,999:INFO:Creating metrics dataframe
2023-03-14 22:59:17,005:INFO:Uploading results into container
2023-03-14 22:59:17,006:INFO:Uploading model into container now
2023-03-14 22:59:17,006:INFO:create_model_container: 8
2023-03-14 22:59:17,006:INFO:master_model_container: 8
2023-03-14 22:59:17,006:INFO:display_container: 2
2023-03-14 22:59:17,006:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-14 22:59:17,006:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:17,101:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:17,101:INFO:Creating metrics dataframe
2023-03-14 22:59:17,115:INFO:Initializing Ada Boost Classifier
2023-03-14 22:59:17,115:INFO:Total runtime is 0.21287391185760499 minutes
2023-03-14 22:59:17,125:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:17,125:INFO:Initializing create_model()
2023-03-14 22:59:17,126:INFO:create_model(estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:17,126:INFO:Checking exceptions
2023-03-14 22:59:17,126:INFO:Importing libraries
2023-03-14 22:59:17,126:INFO:Copying training dataset
2023-03-14 22:59:17,127:INFO:Defining folds
2023-03-14 22:59:17,127:INFO:Declaring metric variables
2023-03-14 22:59:17,135:INFO:Importing untrained model
2023-03-14 22:59:17,145:INFO:Ada Boost Classifier Imported succesfully
2023-03-14 22:59:17,164:INFO:Starting cross validation
2023-03-14 22:59:17,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:17,448:INFO:Calculating mean and std
2023-03-14 22:59:17,449:INFO:Creating metrics dataframe
2023-03-14 22:59:17,452:INFO:Uploading results into container
2023-03-14 22:59:17,453:INFO:Uploading model into container now
2023-03-14 22:59:17,453:INFO:create_model_container: 9
2023-03-14 22:59:17,453:INFO:master_model_container: 9
2023-03-14 22:59:17,453:INFO:display_container: 2
2023-03-14 22:59:17,453:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-03-14 22:59:17,453:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:17,534:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:17,534:INFO:Creating metrics dataframe
2023-03-14 22:59:17,545:INFO:Initializing Gradient Boosting Classifier
2023-03-14 22:59:17,546:INFO:Total runtime is 0.22006316979726157 minutes
2023-03-14 22:59:17,553:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:17,554:INFO:Initializing create_model()
2023-03-14 22:59:17,554:INFO:create_model(estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:17,554:INFO:Checking exceptions
2023-03-14 22:59:17,554:INFO:Importing libraries
2023-03-14 22:59:17,554:INFO:Copying training dataset
2023-03-14 22:59:17,555:INFO:Defining folds
2023-03-14 22:59:17,556:INFO:Declaring metric variables
2023-03-14 22:59:17,563:INFO:Importing untrained model
2023-03-14 22:59:17,571:INFO:Gradient Boosting Classifier Imported succesfully
2023-03-14 22:59:17,588:INFO:Starting cross validation
2023-03-14 22:59:17,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:18,063:INFO:Calculating mean and std
2023-03-14 22:59:18,064:INFO:Creating metrics dataframe
2023-03-14 22:59:18,069:INFO:Uploading results into container
2023-03-14 22:59:18,069:INFO:Uploading model into container now
2023-03-14 22:59:18,069:INFO:create_model_container: 10
2023-03-14 22:59:18,069:INFO:master_model_container: 10
2023-03-14 22:59:18,070:INFO:display_container: 2
2023-03-14 22:59:18,070:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-14 22:59:18,070:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:18,152:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:18,152:INFO:Creating metrics dataframe
2023-03-14 22:59:18,163:INFO:Initializing Linear Discriminant Analysis
2023-03-14 22:59:18,164:INFO:Total runtime is 0.2303603728612264 minutes
2023-03-14 22:59:18,171:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:18,171:INFO:Initializing create_model()
2023-03-14 22:59:18,171:INFO:create_model(estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:18,171:INFO:Checking exceptions
2023-03-14 22:59:18,172:INFO:Importing libraries
2023-03-14 22:59:18,172:INFO:Copying training dataset
2023-03-14 22:59:18,173:INFO:Defining folds
2023-03-14 22:59:18,174:INFO:Declaring metric variables
2023-03-14 22:59:18,180:INFO:Importing untrained model
2023-03-14 22:59:18,187:INFO:Linear Discriminant Analysis Imported succesfully
2023-03-14 22:59:18,201:INFO:Starting cross validation
2023-03-14 22:59:18,202:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:18,247:INFO:Calculating mean and std
2023-03-14 22:59:18,248:INFO:Creating metrics dataframe
2023-03-14 22:59:18,251:INFO:Uploading results into container
2023-03-14 22:59:18,252:INFO:Uploading model into container now
2023-03-14 22:59:18,252:INFO:create_model_container: 11
2023-03-14 22:59:18,252:INFO:master_model_container: 11
2023-03-14 22:59:18,252:INFO:display_container: 2
2023-03-14 22:59:18,252:INFO:LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
                           solver='svd', store_covariance=False, tol=0.0001)
2023-03-14 22:59:18,252:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:18,336:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:18,336:INFO:Creating metrics dataframe
2023-03-14 22:59:18,347:INFO:Initializing Extra Trees Classifier
2023-03-14 22:59:18,347:INFO:Total runtime is 0.23340022563934326 minutes
2023-03-14 22:59:18,355:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:18,355:INFO:Initializing create_model()
2023-03-14 22:59:18,355:INFO:create_model(estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:18,356:INFO:Checking exceptions
2023-03-14 22:59:18,356:INFO:Importing libraries
2023-03-14 22:59:18,356:INFO:Copying training dataset
2023-03-14 22:59:18,357:INFO:Defining folds
2023-03-14 22:59:18,358:INFO:Declaring metric variables
2023-03-14 22:59:18,365:INFO:Importing untrained model
2023-03-14 22:59:18,371:INFO:Extra Trees Classifier Imported succesfully
2023-03-14 22:59:18,386:INFO:Starting cross validation
2023-03-14 22:59:18,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:19,000:INFO:Calculating mean and std
2023-03-14 22:59:19,001:INFO:Creating metrics dataframe
2023-03-14 22:59:19,005:INFO:Uploading results into container
2023-03-14 22:59:19,005:INFO:Uploading model into container now
2023-03-14 22:59:19,005:INFO:create_model_container: 12
2023-03-14 22:59:19,006:INFO:master_model_container: 12
2023-03-14 22:59:19,006:INFO:display_container: 2
2023-03-14 22:59:19,006:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_impurity_split=None,
                     min_samples_leaf=1, min_samples_split=2,
                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2023-03-14 22:59:19,006:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:19,087:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:19,088:INFO:Creating metrics dataframe
2023-03-14 22:59:19,099:INFO:Initializing Light Gradient Boosting Machine
2023-03-14 22:59:19,099:INFO:Total runtime is 0.24593913952509563 minutes
2023-03-14 22:59:19,109:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:19,109:INFO:Initializing create_model()
2023-03-14 22:59:19,109:INFO:create_model(estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:19,110:INFO:Checking exceptions
2023-03-14 22:59:19,110:INFO:Importing libraries
2023-03-14 22:59:19,110:INFO:Copying training dataset
2023-03-14 22:59:19,111:INFO:Defining folds
2023-03-14 22:59:19,111:INFO:Declaring metric variables
2023-03-14 22:59:19,118:INFO:Importing untrained model
2023-03-14 22:59:19,125:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 22:59:19,141:INFO:Starting cross validation
2023-03-14 22:59:19,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:19,333:INFO:Calculating mean and std
2023-03-14 22:59:19,334:INFO:Creating metrics dataframe
2023-03-14 22:59:19,338:INFO:Uploading results into container
2023-03-14 22:59:19,338:INFO:Uploading model into container now
2023-03-14 22:59:19,338:INFO:create_model_container: 13
2023-03-14 22:59:19,339:INFO:master_model_container: 13
2023-03-14 22:59:19,339:INFO:display_container: 2
2023-03-14 22:59:19,339:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 22:59:19,339:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:19,434:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:19,434:INFO:Creating metrics dataframe
2023-03-14 22:59:19,448:INFO:Initializing Dummy Classifier
2023-03-14 22:59:19,448:INFO:Total runtime is 0.251764710744222 minutes
2023-03-14 22:59:19,455:INFO:SubProcess create_model() called ==================================
2023-03-14 22:59:19,456:INFO:Initializing create_model()
2023-03-14 22:59:19,456:INFO:create_model(estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BCB8B0>, return_train_score=False, kwargs={})
2023-03-14 22:59:19,456:INFO:Checking exceptions
2023-03-14 22:59:19,456:INFO:Importing libraries
2023-03-14 22:59:19,457:INFO:Copying training dataset
2023-03-14 22:59:19,458:INFO:Defining folds
2023-03-14 22:59:19,458:INFO:Declaring metric variables
2023-03-14 22:59:19,464:INFO:Importing untrained model
2023-03-14 22:59:19,472:INFO:Dummy Classifier Imported succesfully
2023-03-14 22:59:19,488:INFO:Starting cross validation
2023-03-14 22:59:19,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 22:59:19,517:INFO:Calculating mean and std
2023-03-14 22:59:19,518:INFO:Creating metrics dataframe
2023-03-14 22:59:19,522:INFO:Uploading results into container
2023-03-14 22:59:19,523:INFO:Uploading model into container now
2023-03-14 22:59:19,523:INFO:create_model_container: 14
2023-03-14 22:59:19,523:INFO:master_model_container: 14
2023-03-14 22:59:19,523:INFO:display_container: 2
2023-03-14 22:59:19,524:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-03-14 22:59:19,524:INFO:create_model() succesfully completed......................................
2023-03-14 22:59:19,605:INFO:SubProcess create_model() end ==================================
2023-03-14 22:59:19,606:INFO:Creating metrics dataframe
2023-03-14 22:59:19,637:INFO:Initializing create_model()
2023-03-14 22:59:19,637:INFO:create_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 22:59:19,638:INFO:Checking exceptions
2023-03-14 22:59:19,638:INFO:Importing libraries
2023-03-14 22:59:19,638:INFO:Copying training dataset
2023-03-14 22:59:19,638:INFO:Defining folds
2023-03-14 22:59:19,638:INFO:Declaring metric variables
2023-03-14 22:59:19,638:INFO:Importing untrained model
2023-03-14 22:59:19,638:INFO:Declaring custom model
2023-03-14 22:59:19,640:INFO:Random Forest Classifier Imported succesfully
2023-03-14 22:59:19,640:INFO:Cross validation set to False
2023-03-14 22:59:19,640:INFO:Fitting Model
2023-03-14 22:59:19,872:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2023-03-14 22:59:19,872:INFO:create_models() succesfully completed......................................
2023-03-14 22:59:19,980:INFO:create_model_container: 14
2023-03-14 22:59:19,980:INFO:master_model_container: 14
2023-03-14 22:59:19,981:INFO:display_container: 2
2023-03-14 22:59:19,981:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2023-03-14 22:59:19,981:INFO:compare_models() succesfully completed......................................
2023-03-14 23:00:17,017:INFO:Initializing create_model()
2023-03-14 23:00:17,018:INFO:create_model(estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 23:00:17,018:INFO:Checking exceptions
2023-03-14 23:00:17,018:INFO:Preparing display monitor
2023-03-14 23:00:17,036:INFO:Importing libraries
2023-03-14 23:00:17,036:INFO:Copying training dataset
2023-03-14 23:00:17,037:INFO:Defining folds
2023-03-14 23:00:17,037:INFO:Declaring metric variables
2023-03-14 23:00:17,047:INFO:Importing untrained model
2023-03-14 23:00:17,057:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 23:00:17,077:INFO:Starting cross validation
2023-03-14 23:00:17,078:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:00:17,347:INFO:Calculating mean and std
2023-03-14 23:00:17,348:INFO:Creating metrics dataframe
2023-03-14 23:00:17,358:INFO:Finalizing model
2023-03-14 23:00:17,453:INFO:Uploading results into container
2023-03-14 23:00:17,453:INFO:Uploading model into container now
2023-03-14 23:00:17,467:INFO:create_model_container: 15
2023-03-14 23:00:17,467:INFO:master_model_container: 15
2023-03-14 23:00:17,468:INFO:display_container: 3
2023-03-14 23:00:17,469:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:00:17,469:INFO:create_model() succesfully completed......................................
2023-03-14 23:00:49,848:INFO:Initializing tune_model()
2023-03-14 23:00:49,848:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=False, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-03-14 23:00:49,848:INFO:Checking exceptions
2023-03-14 23:00:49,850:INFO:Preparing display monitor
2023-03-14 23:00:49,875:INFO:Copying training dataset
2023-03-14 23:00:49,877:INFO:Checking base model
2023-03-14 23:00:49,877:INFO:Base model : Light Gradient Boosting Machine
2023-03-14 23:00:49,887:INFO:Declaring metric variables
2023-03-14 23:00:49,896:INFO:Defining Hyperparameters
2023-03-14 23:00:49,997:INFO:Tuning with n_jobs=-1
2023-03-14 23:00:49,997:INFO:Initializing RandomizedSearchCV
2023-03-14 23:00:51,078:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2023-03-14 23:00:51,079:INFO:Hyperparameter search completed
2023-03-14 23:00:51,079:INFO:SubProcess create_model() called ==================================
2023-03-14 23:00:51,080:INFO:Initializing create_model()
2023-03-14 23:00:51,080:INFO:create_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D3B1430>, return_train_score=False, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2023-03-14 23:00:51,080:INFO:Checking exceptions
2023-03-14 23:00:51,080:INFO:Importing libraries
2023-03-14 23:00:51,080:INFO:Copying training dataset
2023-03-14 23:00:51,081:INFO:Defining folds
2023-03-14 23:00:51,081:INFO:Declaring metric variables
2023-03-14 23:00:51,089:INFO:Importing untrained model
2023-03-14 23:00:51,090:INFO:Declaring custom model
2023-03-14 23:00:51,098:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 23:00:51,117:INFO:Starting cross validation
2023-03-14 23:00:51,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:00:51,309:INFO:Calculating mean and std
2023-03-14 23:00:51,310:INFO:Creating metrics dataframe
2023-03-14 23:00:51,319:INFO:Finalizing model
2023-03-14 23:00:51,420:INFO:Uploading results into container
2023-03-14 23:00:51,421:INFO:Uploading model into container now
2023-03-14 23:00:51,421:INFO:create_model_container: 16
2023-03-14 23:00:51,421:INFO:master_model_container: 16
2023-03-14 23:00:51,421:INFO:display_container: 4
2023-03-14 23:00:51,422:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:00:51,422:INFO:create_model() succesfully completed......................................
2023-03-14 23:00:51,530:INFO:SubProcess create_model() end ==================================
2023-03-14 23:00:51,540:INFO:create_model_container: 16
2023-03-14 23:00:51,540:INFO:master_model_container: 16
2023-03-14 23:00:51,540:INFO:display_container: 4
2023-03-14 23:00:51,541:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:00:51,541:INFO:tune_model() succesfully completed......................................
2023-03-14 23:02:29,306:INFO:Initializing tune_model()
2023-03-14 23:02:29,306:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=False, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-03-14 23:02:29,307:INFO:Checking exceptions
2023-03-14 23:02:29,308:INFO:Preparing display monitor
2023-03-14 23:02:29,331:INFO:Copying training dataset
2023-03-14 23:02:29,333:INFO:Checking base model
2023-03-14 23:02:29,333:INFO:Base model : Light Gradient Boosting Machine
2023-03-14 23:02:29,345:INFO:Declaring metric variables
2023-03-14 23:02:29,356:INFO:Defining Hyperparameters
2023-03-14 23:02:29,493:INFO:Tuning with n_jobs=-1
2023-03-14 23:02:29,495:INFO:Initializing RandomizedSearchCV
2023-03-14 23:02:30,679:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2023-03-14 23:02:30,680:INFO:Hyperparameter search completed
2023-03-14 23:02:30,680:INFO:SubProcess create_model() called ==================================
2023-03-14 23:02:30,681:INFO:Initializing create_model()
2023-03-14 23:02:30,681:INFO:create_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D3E3A00>, return_train_score=False, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2023-03-14 23:02:30,681:INFO:Checking exceptions
2023-03-14 23:02:30,681:INFO:Importing libraries
2023-03-14 23:02:30,681:INFO:Copying training dataset
2023-03-14 23:02:30,682:INFO:Defining folds
2023-03-14 23:02:30,682:INFO:Declaring metric variables
2023-03-14 23:02:30,692:INFO:Importing untrained model
2023-03-14 23:02:30,693:INFO:Declaring custom model
2023-03-14 23:02:30,703:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 23:02:30,722:INFO:Starting cross validation
2023-03-14 23:02:30,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:02:30,915:INFO:Calculating mean and std
2023-03-14 23:02:30,916:INFO:Creating metrics dataframe
2023-03-14 23:02:30,927:INFO:Finalizing model
2023-03-14 23:02:31,027:INFO:Uploading results into container
2023-03-14 23:02:31,027:INFO:Uploading model into container now
2023-03-14 23:02:31,028:INFO:create_model_container: 17
2023-03-14 23:02:31,028:INFO:master_model_container: 17
2023-03-14 23:02:31,028:INFO:display_container: 5
2023-03-14 23:02:31,029:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:02:31,029:INFO:create_model() succesfully completed......................................
2023-03-14 23:02:31,134:INFO:SubProcess create_model() end ==================================
2023-03-14 23:02:31,143:INFO:create_model_container: 17
2023-03-14 23:02:31,143:INFO:master_model_container: 17
2023-03-14 23:02:31,143:INFO:display_container: 5
2023-03-14 23:02:31,144:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:02:31,144:INFO:tune_model() succesfully completed......................................
2023-03-14 23:03:13,179:INFO:Initializing tune_model()
2023-03-14 23:03:13,179:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=False, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-03-14 23:03:13,179:INFO:Checking exceptions
2023-03-14 23:03:13,181:INFO:Preparing display monitor
2023-03-14 23:03:13,199:INFO:Copying training dataset
2023-03-14 23:03:13,201:INFO:Checking base model
2023-03-14 23:03:13,201:INFO:Base model : Light Gradient Boosting Machine
2023-03-14 23:03:13,213:INFO:Declaring metric variables
2023-03-14 23:03:13,224:INFO:Defining Hyperparameters
2023-03-14 23:03:13,368:INFO:Tuning with n_jobs=-1
2023-03-14 23:03:13,368:INFO:Initializing RandomizedSearchCV
2023-03-14 23:03:14,541:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2023-03-14 23:03:14,542:INFO:Hyperparameter search completed
2023-03-14 23:03:14,542:INFO:SubProcess create_model() called ==================================
2023-03-14 23:03:14,543:INFO:Initializing create_model()
2023-03-14 23:03:14,543:INFO:create_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D6FEEB0>, return_train_score=False, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2023-03-14 23:03:14,543:INFO:Checking exceptions
2023-03-14 23:03:14,543:INFO:Importing libraries
2023-03-14 23:03:14,543:INFO:Copying training dataset
2023-03-14 23:03:14,544:INFO:Defining folds
2023-03-14 23:03:14,545:INFO:Declaring metric variables
2023-03-14 23:03:14,554:INFO:Importing untrained model
2023-03-14 23:03:14,554:INFO:Declaring custom model
2023-03-14 23:03:14,563:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 23:03:14,583:INFO:Starting cross validation
2023-03-14 23:03:14,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:03:14,766:INFO:Calculating mean and std
2023-03-14 23:03:14,767:INFO:Creating metrics dataframe
2023-03-14 23:03:14,777:INFO:Finalizing model
2023-03-14 23:03:14,875:INFO:Uploading results into container
2023-03-14 23:03:14,876:INFO:Uploading model into container now
2023-03-14 23:03:14,876:INFO:create_model_container: 18
2023-03-14 23:03:14,876:INFO:master_model_container: 18
2023-03-14 23:03:14,876:INFO:display_container: 6
2023-03-14 23:03:14,877:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:03:14,878:INFO:create_model() succesfully completed......................................
2023-03-14 23:03:14,983:INFO:SubProcess create_model() end ==================================
2023-03-14 23:03:14,991:INFO:create_model_container: 18
2023-03-14 23:03:14,991:INFO:master_model_container: 18
2023-03-14 23:03:14,992:INFO:display_container: 6
2023-03-14 23:03:14,992:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:03:14,993:INFO:tune_model() succesfully completed......................................
2023-03-14 23:03:27,859:INFO:Initializing tune_model()
2023-03-14 23:03:27,860:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=False, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-03-14 23:03:27,860:INFO:Checking exceptions
2023-03-14 23:03:27,862:INFO:Preparing display monitor
2023-03-14 23:03:27,880:INFO:Copying training dataset
2023-03-14 23:03:27,881:INFO:Checking base model
2023-03-14 23:03:27,881:INFO:Base model : Light Gradient Boosting Machine
2023-03-14 23:03:27,894:INFO:Declaring metric variables
2023-03-14 23:03:27,905:INFO:Defining Hyperparameters
2023-03-14 23:03:28,031:INFO:Tuning with n_jobs=-1
2023-03-14 23:03:28,031:INFO:Initializing RandomizedSearchCV
2023-03-14 23:03:29,188:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2023-03-14 23:03:29,188:INFO:Hyperparameter search completed
2023-03-14 23:03:29,188:INFO:SubProcess create_model() called ==================================
2023-03-14 23:03:29,189:INFO:Initializing create_model()
2023-03-14 23:03:29,190:INFO:create_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D5AB5B0>, return_train_score=False, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2023-03-14 23:03:29,190:INFO:Checking exceptions
2023-03-14 23:03:29,190:INFO:Importing libraries
2023-03-14 23:03:29,190:INFO:Copying training dataset
2023-03-14 23:03:29,191:INFO:Defining folds
2023-03-14 23:03:29,192:INFO:Declaring metric variables
2023-03-14 23:03:29,201:INFO:Importing untrained model
2023-03-14 23:03:29,201:INFO:Declaring custom model
2023-03-14 23:03:29,212:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 23:03:29,235:INFO:Starting cross validation
2023-03-14 23:03:29,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:03:29,475:INFO:Calculating mean and std
2023-03-14 23:03:29,476:INFO:Creating metrics dataframe
2023-03-14 23:03:29,486:INFO:Finalizing model
2023-03-14 23:03:29,589:INFO:Uploading results into container
2023-03-14 23:03:29,589:INFO:Uploading model into container now
2023-03-14 23:03:29,589:INFO:create_model_container: 19
2023-03-14 23:03:29,590:INFO:master_model_container: 19
2023-03-14 23:03:29,590:INFO:display_container: 7
2023-03-14 23:03:29,591:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:03:29,591:INFO:create_model() succesfully completed......................................
2023-03-14 23:03:29,699:INFO:SubProcess create_model() end ==================================
2023-03-14 23:03:29,708:INFO:create_model_container: 19
2023-03-14 23:03:29,708:INFO:master_model_container: 19
2023-03-14 23:03:29,708:INFO:display_container: 7
2023-03-14 23:03:29,709:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:03:29,709:INFO:tune_model() succesfully completed......................................
2023-03-14 23:04:43,117:INFO:Initializing compare_models()
2023-03-14 23:04:43,118:INFO:compare_models(include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=2, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, display=None, exclude=None)
2023-03-14 23:04:43,118:INFO:Checking exceptions
2023-03-14 23:04:43,120:INFO:Preparing display monitor
2023-03-14 23:04:43,120:INFO:Preparing display monitor
2023-03-14 23:04:43,147:INFO:Initializing Logistic Regression
2023-03-14 23:04:43,147:INFO:Total runtime is 0.0 minutes
2023-03-14 23:04:43,156:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:43,156:INFO:Initializing create_model()
2023-03-14 23:04:43,157:INFO:create_model(estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:43,157:INFO:Checking exceptions
2023-03-14 23:04:43,157:INFO:Importing libraries
2023-03-14 23:04:43,157:INFO:Copying training dataset
2023-03-14 23:04:43,158:INFO:Defining folds
2023-03-14 23:04:43,159:INFO:Declaring metric variables
2023-03-14 23:04:43,168:INFO:Importing untrained model
2023-03-14 23:04:43,177:INFO:Logistic Regression Imported succesfully
2023-03-14 23:04:43,197:INFO:Starting cross validation
2023-03-14 23:04:43,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:43,798:INFO:Calculating mean and std
2023-03-14 23:04:43,799:INFO:Creating metrics dataframe
2023-03-14 23:04:43,804:INFO:Uploading results into container
2023-03-14 23:04:43,804:INFO:Uploading model into container now
2023-03-14 23:04:43,804:INFO:create_model_container: 20
2023-03-14 23:04:43,805:INFO:master_model_container: 20
2023-03-14 23:04:43,805:INFO:display_container: 8
2023-03-14 23:04:43,805:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-14 23:04:43,805:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:43,899:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:43,899:INFO:Creating metrics dataframe
2023-03-14 23:04:43,910:INFO:Initializing K Neighbors Classifier
2023-03-14 23:04:43,910:INFO:Total runtime is 0.012706907590230306 minutes
2023-03-14 23:04:43,921:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:43,921:INFO:Initializing create_model()
2023-03-14 23:04:43,922:INFO:create_model(estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:43,922:INFO:Checking exceptions
2023-03-14 23:04:43,922:INFO:Importing libraries
2023-03-14 23:04:43,922:INFO:Copying training dataset
2023-03-14 23:04:43,923:INFO:Defining folds
2023-03-14 23:04:43,923:INFO:Declaring metric variables
2023-03-14 23:04:43,932:INFO:Importing untrained model
2023-03-14 23:04:43,941:INFO:K Neighbors Classifier Imported succesfully
2023-03-14 23:04:43,961:INFO:Starting cross validation
2023-03-14 23:04:43,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:44,068:INFO:Calculating mean and std
2023-03-14 23:04:44,069:INFO:Creating metrics dataframe
2023-03-14 23:04:44,074:INFO:Uploading results into container
2023-03-14 23:04:44,074:INFO:Uploading model into container now
2023-03-14 23:04:44,074:INFO:create_model_container: 21
2023-03-14 23:04:44,074:INFO:master_model_container: 21
2023-03-14 23:04:44,075:INFO:display_container: 8
2023-03-14 23:04:44,075:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-14 23:04:44,075:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:44,169:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:44,169:INFO:Creating metrics dataframe
2023-03-14 23:04:44,181:INFO:Initializing Naive Bayes
2023-03-14 23:04:44,182:INFO:Total runtime is 0.01724173625310262 minutes
2023-03-14 23:04:44,191:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:44,192:INFO:Initializing create_model()
2023-03-14 23:04:44,192:INFO:create_model(estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:44,192:INFO:Checking exceptions
2023-03-14 23:04:44,192:INFO:Importing libraries
2023-03-14 23:04:44,193:INFO:Copying training dataset
2023-03-14 23:04:44,193:INFO:Defining folds
2023-03-14 23:04:44,193:INFO:Declaring metric variables
2023-03-14 23:04:44,203:INFO:Importing untrained model
2023-03-14 23:04:44,215:INFO:Naive Bayes Imported succesfully
2023-03-14 23:04:44,235:INFO:Starting cross validation
2023-03-14 23:04:44,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:44,278:INFO:Calculating mean and std
2023-03-14 23:04:44,279:INFO:Creating metrics dataframe
2023-03-14 23:04:44,285:INFO:Uploading results into container
2023-03-14 23:04:44,285:INFO:Uploading model into container now
2023-03-14 23:04:44,285:INFO:create_model_container: 22
2023-03-14 23:04:44,285:INFO:master_model_container: 22
2023-03-14 23:04:44,285:INFO:display_container: 8
2023-03-14 23:04:44,286:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-14 23:04:44,286:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:44,376:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:44,376:INFO:Creating metrics dataframe
2023-03-14 23:04:44,386:INFO:Initializing Decision Tree Classifier
2023-03-14 23:04:44,386:INFO:Total runtime is 0.020647029081980385 minutes
2023-03-14 23:04:44,395:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:44,396:INFO:Initializing create_model()
2023-03-14 23:04:44,396:INFO:create_model(estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:44,396:INFO:Checking exceptions
2023-03-14 23:04:44,396:INFO:Importing libraries
2023-03-14 23:04:44,396:INFO:Copying training dataset
2023-03-14 23:04:44,397:INFO:Defining folds
2023-03-14 23:04:44,398:INFO:Declaring metric variables
2023-03-14 23:04:44,408:INFO:Importing untrained model
2023-03-14 23:04:44,417:INFO:Decision Tree Classifier Imported succesfully
2023-03-14 23:04:44,437:INFO:Starting cross validation
2023-03-14 23:04:44,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:44,485:INFO:Calculating mean and std
2023-03-14 23:04:44,486:INFO:Creating metrics dataframe
2023-03-14 23:04:44,490:INFO:Uploading results into container
2023-03-14 23:04:44,490:INFO:Uploading model into container now
2023-03-14 23:04:44,490:INFO:create_model_container: 23
2023-03-14 23:04:44,490:INFO:master_model_container: 23
2023-03-14 23:04:44,490:INFO:display_container: 8
2023-03-14 23:04:44,491:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=42, splitter='best')
2023-03-14 23:04:44,491:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:44,578:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:44,578:INFO:Creating metrics dataframe
2023-03-14 23:04:44,589:INFO:Initializing SVM - Linear Kernel
2023-03-14 23:04:44,590:INFO:Total runtime is 0.024049337704976397 minutes
2023-03-14 23:04:44,599:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:44,599:INFO:Initializing create_model()
2023-03-14 23:04:44,599:INFO:create_model(estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:44,600:INFO:Checking exceptions
2023-03-14 23:04:44,600:INFO:Importing libraries
2023-03-14 23:04:44,600:INFO:Copying training dataset
2023-03-14 23:04:44,601:INFO:Defining folds
2023-03-14 23:04:44,601:INFO:Declaring metric variables
2023-03-14 23:04:44,611:INFO:Importing untrained model
2023-03-14 23:04:44,621:INFO:SVM - Linear Kernel Imported succesfully
2023-03-14 23:04:44,641:INFO:Starting cross validation
2023-03-14 23:04:44,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:44,684:INFO:Calculating mean and std
2023-03-14 23:04:44,684:INFO:Creating metrics dataframe
2023-03-14 23:04:44,690:INFO:Uploading results into container
2023-03-14 23:04:44,691:INFO:Uploading model into container now
2023-03-14 23:04:44,691:INFO:create_model_container: 24
2023-03-14 23:04:44,691:INFO:master_model_container: 24
2023-03-14 23:04:44,691:INFO:display_container: 8
2023-03-14 23:04:44,692:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-14 23:04:44,692:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:44,777:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:44,777:INFO:Creating metrics dataframe
2023-03-14 23:04:44,790:INFO:Initializing Ridge Classifier
2023-03-14 23:04:44,791:INFO:Total runtime is 0.02740125258763631 minutes
2023-03-14 23:04:44,801:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:44,801:INFO:Initializing create_model()
2023-03-14 23:04:44,802:INFO:create_model(estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:44,802:INFO:Checking exceptions
2023-03-14 23:04:44,802:INFO:Importing libraries
2023-03-14 23:04:44,802:INFO:Copying training dataset
2023-03-14 23:04:44,803:INFO:Defining folds
2023-03-14 23:04:44,803:INFO:Declaring metric variables
2023-03-14 23:04:44,811:INFO:Importing untrained model
2023-03-14 23:04:44,820:INFO:Ridge Classifier Imported succesfully
2023-03-14 23:04:44,839:INFO:Starting cross validation
2023-03-14 23:04:44,840:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:44,873:INFO:Calculating mean and std
2023-03-14 23:04:44,874:INFO:Creating metrics dataframe
2023-03-14 23:04:44,878:INFO:Uploading results into container
2023-03-14 23:04:44,879:INFO:Uploading model into container now
2023-03-14 23:04:44,879:INFO:create_model_container: 25
2023-03-14 23:04:44,879:INFO:master_model_container: 25
2023-03-14 23:04:44,879:INFO:display_container: 8
2023-03-14 23:04:44,880:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize=False, random_state=42, solver='auto',
                tol=0.001)
2023-03-14 23:04:44,880:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:44,982:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:44,982:INFO:Creating metrics dataframe
2023-03-14 23:04:44,994:INFO:Initializing Random Forest Classifier
2023-03-14 23:04:44,994:INFO:Total runtime is 0.03077356417973836 minutes
2023-03-14 23:04:45,005:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:45,005:INFO:Initializing create_model()
2023-03-14 23:04:45,005:INFO:create_model(estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:45,006:INFO:Checking exceptions
2023-03-14 23:04:45,006:INFO:Importing libraries
2023-03-14 23:04:45,006:INFO:Copying training dataset
2023-03-14 23:04:45,007:INFO:Defining folds
2023-03-14 23:04:45,007:INFO:Declaring metric variables
2023-03-14 23:04:45,015:INFO:Importing untrained model
2023-03-14 23:04:45,024:INFO:Random Forest Classifier Imported succesfully
2023-03-14 23:04:45,042:INFO:Starting cross validation
2023-03-14 23:04:45,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:45,781:INFO:Calculating mean and std
2023-03-14 23:04:45,781:INFO:Creating metrics dataframe
2023-03-14 23:04:45,786:INFO:Uploading results into container
2023-03-14 23:04:45,786:INFO:Uploading model into container now
2023-03-14 23:04:45,786:INFO:create_model_container: 26
2023-03-14 23:04:45,786:INFO:master_model_container: 26
2023-03-14 23:04:45,786:INFO:display_container: 8
2023-03-14 23:04:45,787:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2023-03-14 23:04:45,787:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:45,876:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:45,876:INFO:Creating metrics dataframe
2023-03-14 23:04:45,887:INFO:Initializing Quadratic Discriminant Analysis
2023-03-14 23:04:45,887:INFO:Total runtime is 0.04566218058268229 minutes
2023-03-14 23:04:45,896:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:45,897:INFO:Initializing create_model()
2023-03-14 23:04:45,897:INFO:create_model(estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:45,897:INFO:Checking exceptions
2023-03-14 23:04:45,898:INFO:Importing libraries
2023-03-14 23:04:45,898:INFO:Copying training dataset
2023-03-14 23:04:45,899:INFO:Defining folds
2023-03-14 23:04:45,899:INFO:Declaring metric variables
2023-03-14 23:04:45,907:INFO:Importing untrained model
2023-03-14 23:04:45,915:INFO:Quadratic Discriminant Analysis Imported succesfully
2023-03-14 23:04:45,936:INFO:Starting cross validation
2023-03-14 23:04:45,936:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:45,978:INFO:Calculating mean and std
2023-03-14 23:04:45,979:INFO:Creating metrics dataframe
2023-03-14 23:04:45,983:INFO:Uploading results into container
2023-03-14 23:04:45,984:INFO:Uploading model into container now
2023-03-14 23:04:45,984:INFO:create_model_container: 27
2023-03-14 23:04:45,984:INFO:master_model_container: 27
2023-03-14 23:04:45,984:INFO:display_container: 8
2023-03-14 23:04:45,984:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-14 23:04:45,984:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:46,069:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:46,069:INFO:Creating metrics dataframe
2023-03-14 23:04:46,083:INFO:Initializing Ada Boost Classifier
2023-03-14 23:04:46,083:INFO:Total runtime is 0.048934555053710936 minutes
2023-03-14 23:04:46,093:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:46,094:INFO:Initializing create_model()
2023-03-14 23:04:46,094:INFO:create_model(estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:46,094:INFO:Checking exceptions
2023-03-14 23:04:46,095:INFO:Importing libraries
2023-03-14 23:04:46,095:INFO:Copying training dataset
2023-03-14 23:04:46,096:INFO:Defining folds
2023-03-14 23:04:46,096:INFO:Declaring metric variables
2023-03-14 23:04:46,111:INFO:Importing untrained model
2023-03-14 23:04:46,122:INFO:Ada Boost Classifier Imported succesfully
2023-03-14 23:04:46,141:INFO:Starting cross validation
2023-03-14 23:04:46,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:46,431:INFO:Calculating mean and std
2023-03-14 23:04:46,432:INFO:Creating metrics dataframe
2023-03-14 23:04:46,437:INFO:Uploading results into container
2023-03-14 23:04:46,438:INFO:Uploading model into container now
2023-03-14 23:04:46,438:INFO:create_model_container: 28
2023-03-14 23:04:46,438:INFO:master_model_container: 28
2023-03-14 23:04:46,438:INFO:display_container: 8
2023-03-14 23:04:46,438:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-03-14 23:04:46,438:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:46,524:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:46,524:INFO:Creating metrics dataframe
2023-03-14 23:04:46,536:INFO:Initializing Gradient Boosting Classifier
2023-03-14 23:04:46,536:INFO:Total runtime is 0.05647596120834351 minutes
2023-03-14 23:04:46,544:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:46,545:INFO:Initializing create_model()
2023-03-14 23:04:46,545:INFO:create_model(estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:46,545:INFO:Checking exceptions
2023-03-14 23:04:46,545:INFO:Importing libraries
2023-03-14 23:04:46,546:INFO:Copying training dataset
2023-03-14 23:04:46,547:INFO:Defining folds
2023-03-14 23:04:46,547:INFO:Declaring metric variables
2023-03-14 23:04:46,555:INFO:Importing untrained model
2023-03-14 23:04:46,564:INFO:Gradient Boosting Classifier Imported succesfully
2023-03-14 23:04:46,582:INFO:Starting cross validation
2023-03-14 23:04:46,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:47,110:INFO:Calculating mean and std
2023-03-14 23:04:47,111:INFO:Creating metrics dataframe
2023-03-14 23:04:47,115:INFO:Uploading results into container
2023-03-14 23:04:47,115:INFO:Uploading model into container now
2023-03-14 23:04:47,115:INFO:create_model_container: 29
2023-03-14 23:04:47,115:INFO:master_model_container: 29
2023-03-14 23:04:47,116:INFO:display_container: 8
2023-03-14 23:04:47,117:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-14 23:04:47,117:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:47,203:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:47,203:INFO:Creating metrics dataframe
2023-03-14 23:04:47,216:INFO:Initializing Linear Discriminant Analysis
2023-03-14 23:04:47,216:INFO:Total runtime is 0.06781890789667766 minutes
2023-03-14 23:04:47,224:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:47,224:INFO:Initializing create_model()
2023-03-14 23:04:47,224:INFO:create_model(estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:47,224:INFO:Checking exceptions
2023-03-14 23:04:47,225:INFO:Importing libraries
2023-03-14 23:04:47,225:INFO:Copying training dataset
2023-03-14 23:04:47,226:INFO:Defining folds
2023-03-14 23:04:47,226:INFO:Declaring metric variables
2023-03-14 23:04:47,235:INFO:Importing untrained model
2023-03-14 23:04:47,243:INFO:Linear Discriminant Analysis Imported succesfully
2023-03-14 23:04:47,262:INFO:Starting cross validation
2023-03-14 23:04:47,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:47,308:INFO:Calculating mean and std
2023-03-14 23:04:47,309:INFO:Creating metrics dataframe
2023-03-14 23:04:47,315:INFO:Uploading results into container
2023-03-14 23:04:47,316:INFO:Uploading model into container now
2023-03-14 23:04:47,316:INFO:create_model_container: 30
2023-03-14 23:04:47,316:INFO:master_model_container: 30
2023-03-14 23:04:47,316:INFO:display_container: 8
2023-03-14 23:04:47,317:INFO:LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
                           solver='svd', store_covariance=False, tol=0.0001)
2023-03-14 23:04:47,317:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:47,402:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:47,402:INFO:Creating metrics dataframe
2023-03-14 23:04:47,428:INFO:Initializing Extra Trees Classifier
2023-03-14 23:04:47,428:INFO:Total runtime is 0.07134039799372356 minutes
2023-03-14 23:04:47,440:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:47,441:INFO:Initializing create_model()
2023-03-14 23:04:47,441:INFO:create_model(estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:47,441:INFO:Checking exceptions
2023-03-14 23:04:47,442:INFO:Importing libraries
2023-03-14 23:04:47,442:INFO:Copying training dataset
2023-03-14 23:04:47,443:INFO:Defining folds
2023-03-14 23:04:47,443:INFO:Declaring metric variables
2023-03-14 23:04:47,455:INFO:Importing untrained model
2023-03-14 23:04:47,465:INFO:Extra Trees Classifier Imported succesfully
2023-03-14 23:04:47,483:INFO:Starting cross validation
2023-03-14 23:04:47,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:48,131:INFO:Calculating mean and std
2023-03-14 23:04:48,132:INFO:Creating metrics dataframe
2023-03-14 23:04:48,137:INFO:Uploading results into container
2023-03-14 23:04:48,137:INFO:Uploading model into container now
2023-03-14 23:04:48,137:INFO:create_model_container: 31
2023-03-14 23:04:48,137:INFO:master_model_container: 31
2023-03-14 23:04:48,137:INFO:display_container: 8
2023-03-14 23:04:48,138:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_impurity_split=None,
                     min_samples_leaf=1, min_samples_split=2,
                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2023-03-14 23:04:48,138:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:48,230:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:48,230:INFO:Creating metrics dataframe
2023-03-14 23:04:48,244:INFO:Initializing Light Gradient Boosting Machine
2023-03-14 23:04:48,244:INFO:Total runtime is 0.08494506279627483 minutes
2023-03-14 23:04:48,254:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:48,255:INFO:Initializing create_model()
2023-03-14 23:04:48,255:INFO:create_model(estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:48,255:INFO:Checking exceptions
2023-03-14 23:04:48,255:INFO:Importing libraries
2023-03-14 23:04:48,255:INFO:Copying training dataset
2023-03-14 23:04:48,257:INFO:Defining folds
2023-03-14 23:04:48,257:INFO:Declaring metric variables
2023-03-14 23:04:48,267:INFO:Importing untrained model
2023-03-14 23:04:48,278:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 23:04:48,303:INFO:Starting cross validation
2023-03-14 23:04:48,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:48,502:INFO:Calculating mean and std
2023-03-14 23:04:48,503:INFO:Creating metrics dataframe
2023-03-14 23:04:48,510:INFO:Uploading results into container
2023-03-14 23:04:48,510:INFO:Uploading model into container now
2023-03-14 23:04:48,510:INFO:create_model_container: 32
2023-03-14 23:04:48,511:INFO:master_model_container: 32
2023-03-14 23:04:48,511:INFO:display_container: 8
2023-03-14 23:04:48,511:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:04:48,512:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:48,609:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:48,609:INFO:Creating metrics dataframe
2023-03-14 23:04:48,625:INFO:Initializing Dummy Classifier
2023-03-14 23:04:48,625:INFO:Total runtime is 0.09130184650421143 minutes
2023-03-14 23:04:48,636:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:48,636:INFO:Initializing create_model()
2023-03-14 23:04:48,637:INFO:create_model(estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D77FBE0>, return_train_score=False, kwargs={})
2023-03-14 23:04:48,637:INFO:Checking exceptions
2023-03-14 23:04:48,637:INFO:Importing libraries
2023-03-14 23:04:48,637:INFO:Copying training dataset
2023-03-14 23:04:48,638:INFO:Defining folds
2023-03-14 23:04:48,638:INFO:Declaring metric variables
2023-03-14 23:04:48,647:INFO:Importing untrained model
2023-03-14 23:04:48,656:INFO:Dummy Classifier Imported succesfully
2023-03-14 23:04:48,676:INFO:Starting cross validation
2023-03-14 23:04:48,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:48,705:INFO:Calculating mean and std
2023-03-14 23:04:48,706:INFO:Creating metrics dataframe
2023-03-14 23:04:48,710:INFO:Uploading results into container
2023-03-14 23:04:48,710:INFO:Uploading model into container now
2023-03-14 23:04:48,710:INFO:create_model_container: 33
2023-03-14 23:04:48,710:INFO:master_model_container: 33
2023-03-14 23:04:48,710:INFO:display_container: 8
2023-03-14 23:04:48,711:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-03-14 23:04:48,711:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:48,795:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:48,795:INFO:Creating metrics dataframe
2023-03-14 23:04:48,828:INFO:Initializing create_model()
2023-03-14 23:04:48,828:INFO:create_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 23:04:48,828:INFO:Checking exceptions
2023-03-14 23:04:48,829:INFO:Importing libraries
2023-03-14 23:04:48,829:INFO:Copying training dataset
2023-03-14 23:04:48,829:INFO:Defining folds
2023-03-14 23:04:48,829:INFO:Declaring metric variables
2023-03-14 23:04:48,829:INFO:Importing untrained model
2023-03-14 23:04:48,829:INFO:Declaring custom model
2023-03-14 23:04:48,830:INFO:Random Forest Classifier Imported succesfully
2023-03-14 23:04:48,831:INFO:Cross validation set to False
2023-03-14 23:04:48,831:INFO:Fitting Model
2023-03-14 23:04:49,081:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2023-03-14 23:04:49,081:INFO:create_models() succesfully completed......................................
2023-03-14 23:04:49,173:INFO:Initializing create_model()
2023-03-14 23:04:49,173:INFO:create_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 23:04:49,173:INFO:Checking exceptions
2023-03-14 23:04:49,173:INFO:Importing libraries
2023-03-14 23:04:49,173:INFO:Copying training dataset
2023-03-14 23:04:49,174:INFO:Defining folds
2023-03-14 23:04:49,174:INFO:Declaring metric variables
2023-03-14 23:04:49,174:INFO:Importing untrained model
2023-03-14 23:04:49,174:INFO:Declaring custom model
2023-03-14 23:04:49,175:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 23:04:49,176:INFO:Cross validation set to False
2023-03-14 23:04:49,176:INFO:Fitting Model
2023-03-14 23:04:49,267:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:04:49,267:INFO:create_models() succesfully completed......................................
2023-03-14 23:04:49,394:INFO:create_model_container: 33
2023-03-14 23:04:49,394:INFO:master_model_container: 33
2023-03-14 23:04:49,394:INFO:display_container: 8
2023-03-14 23:04:49,395:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)]
2023-03-14 23:04:49,396:INFO:compare_models() succesfully completed......................................
2023-03-14 23:04:49,397:INFO:Initializing blend_models()
2023-03-14 23:04:49,397:INFO:blend_models(estimator_list=[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, display=None, return_train_score=False)
2023-03-14 23:04:49,397:INFO:Checking exceptions
2023-03-14 23:04:49,397:INFO:Preparing display monitor
2023-03-14 23:04:49,414:INFO:Importing libraries
2023-03-14 23:04:49,414:INFO:Copying training dataset
2023-03-14 23:04:49,425:INFO:Getting model names
2023-03-14 23:04:49,436:INFO:SubProcess create_model() called ==================================
2023-03-14 23:04:49,441:INFO:Initializing create_model()
2023-03-14 23:04:49,441:INFO:create_model(estimator=VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B548BE32E0>, return_train_score=False, kwargs={})
2023-03-14 23:04:49,441:INFO:Checking exceptions
2023-03-14 23:04:49,442:INFO:Importing libraries
2023-03-14 23:04:49,442:INFO:Copying training dataset
2023-03-14 23:04:49,443:INFO:Defining folds
2023-03-14 23:04:49,443:INFO:Declaring metric variables
2023-03-14 23:04:49,452:INFO:Importing untrained model
2023-03-14 23:04:49,452:INFO:Declaring custom model
2023-03-14 23:04:49,464:INFO:Voting Classifier Imported succesfully
2023-03-14 23:04:49,482:INFO:Starting cross validation
2023-03-14 23:04:49,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:04:50,270:INFO:Calculating mean and std
2023-03-14 23:04:50,271:INFO:Creating metrics dataframe
2023-03-14 23:04:50,282:INFO:Finalizing model
2023-03-14 23:04:50,523:INFO:Uploading results into container
2023-03-14 23:04:50,523:INFO:Uploading model into container now
2023-03-14 23:04:50,523:INFO:create_model_container: 34
2023-03-14 23:04:50,523:INFO:master_model_container: 34
2023-03-14 23:04:50,523:INFO:display_container: 9
2023-03-14 23:04:50,527:INFO:VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:04:50,527:INFO:create_model() succesfully completed......................................
2023-03-14 23:04:50,616:INFO:SubProcess create_model() end ==================================
2023-03-14 23:04:50,625:INFO:create_model_container: 34
2023-03-14 23:04:50,625:INFO:master_model_container: 34
2023-03-14 23:04:50,626:INFO:display_container: 9
2023-03-14 23:04:50,630:INFO:VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:04:50,630:INFO:blend_models() succesfully completed......................................
2023-03-14 23:05:49,606:INFO:Initializing finalize_model()
2023-03-14 23:05:49,606:INFO:finalize_model(estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=True, display=None, experiment_custom_tags=None, return_train_score=False)
2023-03-14 23:05:49,607:INFO:Finalizing LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:05:49,608:INFO:Initializing create_model()
2023-03-14 23:05:49,609:INFO:create_model(estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=False, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 23:05:49,609:INFO:Checking exceptions
2023-03-14 23:05:49,609:INFO:Importing libraries
2023-03-14 23:05:49,609:INFO:Copying training dataset
2023-03-14 23:05:49,610:INFO:Defining folds
2023-03-14 23:05:49,610:INFO:Declaring metric variables
2023-03-14 23:05:49,610:INFO:Importing untrained model
2023-03-14 23:05:49,610:INFO:Declaring custom model
2023-03-14 23:05:49,611:INFO:Light Gradient Boosting Machine Imported succesfully
2023-03-14 23:05:49,611:INFO:Starting cross validation
2023-03-14 23:05:49,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:05:49,873:INFO:Calculating mean and std
2023-03-14 23:05:49,874:INFO:Creating metrics dataframe
2023-03-14 23:05:49,877:INFO:Finalizing model
2023-03-14 23:05:49,979:INFO:create_model_container: 34
2023-03-14 23:05:49,979:INFO:master_model_container: 34
2023-03-14 23:05:49,979:INFO:display_container: 10
2023-03-14 23:05:49,980:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:05:49,980:INFO:create_model() succesfully completed......................................
2023-03-14 23:05:50,079:INFO:create_model_container: 34
2023-03-14 23:05:50,079:INFO:master_model_container: 34
2023-03-14 23:05:50,079:INFO:display_container: 9
2023-03-14 23:05:50,079:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-14 23:05:50,079:INFO:finalize_model() succesfully completed......................................
2023-03-14 23:05:50,173:INFO:Initializing predict_model()
2023-03-14 23:05:50,173:INFO:predict_model(estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, drift_report=False, raw_score=False, round=4, verbose=True, ml_usecase=MLUsecase.CLASSIFICATION, display=None, drift_kwargs=None)
2023-03-14 23:05:50,173:INFO:Checking exceptions
2023-03-14 23:05:50,173:INFO:Preloading libraries
2023-03-14 23:05:50,173:INFO:Preparing display monitor
2023-03-14 23:07:37,554:INFO:Initializing finalize_model()
2023-03-14 23:07:37,554:INFO:finalize_model(estimator=VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=True, display=None, experiment_custom_tags=None, return_train_score=False)
2023-03-14 23:07:37,558:INFO:Finalizing VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:07:37,563:INFO:Initializing create_model()
2023-03-14 23:07:37,564:INFO:create_model(estimator=VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=False, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 23:07:37,564:INFO:Checking exceptions
2023-03-14 23:07:37,564:INFO:Importing libraries
2023-03-14 23:07:37,564:INFO:Copying training dataset
2023-03-14 23:07:37,565:INFO:Defining folds
2023-03-14 23:07:37,565:INFO:Declaring metric variables
2023-03-14 23:07:37,565:INFO:Importing untrained model
2023-03-14 23:07:37,565:INFO:Declaring custom model
2023-03-14 23:07:37,567:INFO:Voting Classifier Imported succesfully
2023-03-14 23:07:37,567:INFO:Starting cross validation
2023-03-14 23:07:37,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:07:38,452:INFO:Calculating mean and std
2023-03-14 23:07:38,453:INFO:Creating metrics dataframe
2023-03-14 23:07:38,456:INFO:Finalizing model
2023-03-14 23:07:38,728:INFO:create_model_container: 34
2023-03-14 23:07:38,728:INFO:master_model_container: 34
2023-03-14 23:07:38,728:INFO:display_container: 10
2023-03-14 23:07:38,731:INFO:VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:07:38,731:INFO:create_model() succesfully completed......................................
2023-03-14 23:07:38,821:INFO:create_model_container: 34
2023-03-14 23:07:38,821:INFO:master_model_container: 34
2023-03-14 23:07:38,821:INFO:display_container: 9
2023-03-14 23:07:38,825:INFO:VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:07:38,825:INFO:finalize_model() succesfully completed......................................
2023-03-14 23:07:38,914:INFO:Initializing predict_model()
2023-03-14 23:07:38,914:INFO:predict_model(estimator=VotingClassifier(estimators=[('rf',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=F...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=42, reg_alpha=0.0,
                                             reg_lambda=0.0, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, drift_report=False, raw_score=False, round=4, verbose=True, ml_usecase=MLUsecase.CLASSIFICATION, display=None, drift_kwargs=None)
2023-03-14 23:07:38,914:INFO:Checking exceptions
2023-03-14 23:07:38,914:INFO:Preloading libraries
2023-03-14 23:07:38,914:INFO:Preparing display monitor
2023-03-14 23:08:29,673:INFO:Initializing create_model()
2023-03-14 23:08:29,673:INFO:create_model(estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 23:08:29,673:INFO:Checking exceptions
2023-03-14 23:08:29,674:INFO:Preparing display monitor
2023-03-14 23:08:29,691:INFO:Importing libraries
2023-03-14 23:08:29,691:INFO:Copying training dataset
2023-03-14 23:08:29,692:INFO:Defining folds
2023-03-14 23:08:29,692:INFO:Declaring metric variables
2023-03-14 23:08:29,700:INFO:Importing untrained model
2023-03-14 23:08:29,710:INFO:Random Forest Classifier Imported succesfully
2023-03-14 23:08:29,728:INFO:Starting cross validation
2023-03-14 23:08:29,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:08:30,508:INFO:Calculating mean and std
2023-03-14 23:08:30,509:INFO:Creating metrics dataframe
2023-03-14 23:08:30,519:INFO:Finalizing model
2023-03-14 23:08:30,786:INFO:Uploading results into container
2023-03-14 23:08:30,787:INFO:Uploading model into container now
2023-03-14 23:08:30,796:INFO:create_model_container: 35
2023-03-14 23:08:30,797:INFO:master_model_container: 35
2023-03-14 23:08:30,797:INFO:display_container: 10
2023-03-14 23:08:30,798:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2023-03-14 23:08:30,798:INFO:create_model() succesfully completed......................................
2023-03-14 23:08:53,614:INFO:Initializing tune_model()
2023-03-14 23:08:53,614:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=False, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, display=None, return_train_score=False, kwargs={})
2023-03-14 23:08:53,614:INFO:Checking exceptions
2023-03-14 23:08:53,615:INFO:Preparing display monitor
2023-03-14 23:08:53,632:INFO:Copying training dataset
2023-03-14 23:08:53,633:INFO:Checking base model
2023-03-14 23:08:53,634:INFO:Base model : Random Forest Classifier
2023-03-14 23:08:53,645:INFO:Declaring metric variables
2023-03-14 23:08:53,660:INFO:Defining Hyperparameters
2023-03-14 23:08:53,783:INFO:Tuning with n_jobs=-1
2023-03-14 23:08:53,783:INFO:Initializing RandomizedSearchCV
2023-03-14 23:09:02,739:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2023-03-14 23:09:02,739:INFO:Hyperparameter search completed
2023-03-14 23:09:02,739:INFO:SubProcess create_model() called ==================================
2023-03-14 23:09:02,740:INFO:Initializing create_model()
2023-03-14 23:09:02,740:INFO:create_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57DD50310>, return_train_score=False, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2023-03-14 23:09:02,740:INFO:Checking exceptions
2023-03-14 23:09:02,740:INFO:Importing libraries
2023-03-14 23:09:02,740:INFO:Copying training dataset
2023-03-14 23:09:02,741:INFO:Defining folds
2023-03-14 23:09:02,742:INFO:Declaring metric variables
2023-03-14 23:09:02,752:INFO:Importing untrained model
2023-03-14 23:09:02,752:INFO:Declaring custom model
2023-03-14 23:09:02,761:INFO:Random Forest Classifier Imported succesfully
2023-03-14 23:09:02,777:INFO:Starting cross validation
2023-03-14 23:09:02,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:09:04,210:INFO:Calculating mean and std
2023-03-14 23:09:04,210:INFO:Creating metrics dataframe
2023-03-14 23:09:04,219:INFO:Finalizing model
2023-03-14 23:09:04,671:INFO:Uploading results into container
2023-03-14 23:09:04,671:INFO:Uploading model into container now
2023-03-14 23:09:04,671:INFO:create_model_container: 36
2023-03-14 23:09:04,671:INFO:master_model_container: 36
2023-03-14 23:09:04,671:INFO:display_container: 11
2023-03-14 23:09:04,672:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_impurity_split=None,
                       min_samples_leaf=6, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=230,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2023-03-14 23:09:04,672:INFO:create_model() succesfully completed......................................
2023-03-14 23:09:04,754:INFO:SubProcess create_model() end ==================================
2023-03-14 23:09:04,764:INFO:create_model_container: 36
2023-03-14 23:09:04,764:INFO:master_model_container: 36
2023-03-14 23:09:04,764:INFO:display_container: 11
2023-03-14 23:09:04,764:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_impurity_split=None,
                       min_samples_leaf=6, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=230,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2023-03-14 23:09:04,764:INFO:tune_model() succesfully completed......................................
2023-03-14 23:10:44,795:INFO:Initializing create_model()
2023-03-14 23:10:44,795:INFO:create_model(estimator=tuned_lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, verbose=True, system=True, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 23:10:44,795:INFO:Checking exceptions
2023-03-14 23:13:04,177:INFO:Initializing blend_models()
2023-03-14 23:13:04,178:INFO:blend_models(estimator_list=[LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_impurity_split=None,
                       min_samples_leaf=6, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=230,
                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, display=None, return_train_score=False)
2023-03-14 23:13:04,178:INFO:Checking exceptions
2023-03-14 23:13:04,179:INFO:Preparing display monitor
2023-03-14 23:13:04,197:INFO:Importing libraries
2023-03-14 23:13:04,197:INFO:Copying training dataset
2023-03-14 23:13:04,208:INFO:Getting model names
2023-03-14 23:13:04,219:INFO:SubProcess create_model() called ==================================
2023-03-14 23:13:04,224:INFO:Initializing create_model()
2023-03-14 23:13:04,225:INFO:create_model(estimator=VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=True, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=True, probability_threshold=None, display=<pycaret.internal.Display.Display object at 0x000002B57D6EE460>, return_train_score=False, kwargs={})
2023-03-14 23:13:04,225:INFO:Checking exceptions
2023-03-14 23:13:04,225:INFO:Importing libraries
2023-03-14 23:13:04,226:INFO:Copying training dataset
2023-03-14 23:13:04,227:INFO:Defining folds
2023-03-14 23:13:04,227:INFO:Declaring metric variables
2023-03-14 23:13:04,237:INFO:Importing untrained model
2023-03-14 23:13:04,238:INFO:Declaring custom model
2023-03-14 23:13:04,261:INFO:Voting Classifier Imported succesfully
2023-03-14 23:13:04,290:INFO:Starting cross validation
2023-03-14 23:13:04,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:13:05,855:INFO:Calculating mean and std
2023-03-14 23:13:05,857:INFO:Creating metrics dataframe
2023-03-14 23:13:05,869:INFO:Finalizing model
2023-03-14 23:13:06,392:INFO:Uploading results into container
2023-03-14 23:13:06,392:INFO:Uploading model into container now
2023-03-14 23:13:06,392:INFO:create_model_container: 37
2023-03-14 23:13:06,392:INFO:master_model_container: 37
2023-03-14 23:13:06,392:INFO:display_container: 12
2023-03-14 23:13:06,398:INFO:VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:13:06,398:INFO:create_model() succesfully completed......................................
2023-03-14 23:13:06,534:INFO:SubProcess create_model() end ==================================
2023-03-14 23:13:06,543:INFO:create_model_container: 37
2023-03-14 23:13:06,543:INFO:master_model_container: 37
2023-03-14 23:13:06,543:INFO:display_container: 12
2023-03-14 23:13:06,548:INFO:VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:13:06,549:INFO:blend_models() succesfully completed......................................
2023-03-14 23:13:31,482:INFO:Initializing finalize_model()
2023-03-14 23:13:31,482:INFO:finalize_model(estimator=VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=True, display=None, experiment_custom_tags=None, return_train_score=False)
2023-03-14 23:13:31,486:INFO:Finalizing VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:13:31,490:INFO:Initializing create_model()
2023-03-14 23:13:31,490:INFO:create_model(estimator=VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, verbose=False, system=False, metrics=None, experiment_custom_tags=None, add_to_model_list=False, probability_threshold=None, display=None, return_train_score=False, kwargs={})
2023-03-14 23:13:31,491:INFO:Checking exceptions
2023-03-14 23:13:31,491:INFO:Importing libraries
2023-03-14 23:13:31,491:INFO:Copying training dataset
2023-03-14 23:13:31,492:INFO:Defining folds
2023-03-14 23:13:31,492:INFO:Declaring metric variables
2023-03-14 23:13:31,492:INFO:Importing untrained model
2023-03-14 23:13:31,492:INFO:Declaring custom model
2023-03-14 23:13:31,495:INFO:Voting Classifier Imported succesfully
2023-03-14 23:13:31,496:INFO:Starting cross validation
2023-03-14 23:13:31,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-14 23:13:33,321:INFO:Calculating mean and std
2023-03-14 23:13:33,322:INFO:Creating metrics dataframe
2023-03-14 23:13:33,325:INFO:Finalizing model
2023-03-14 23:13:33,843:INFO:create_model_container: 37
2023-03-14 23:13:33,844:INFO:master_model_container: 37
2023-03-14 23:13:33,844:INFO:display_container: 13
2023-03-14 23:13:33,847:INFO:VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:13:33,847:INFO:create_model() succesfully completed......................................
2023-03-14 23:13:33,968:INFO:create_model_container: 37
2023-03-14 23:13:33,968:INFO:master_model_container: 37
2023-03-14 23:13:33,968:INFO:display_container: 12
2023-03-14 23:13:33,971:INFO:VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-03-14 23:13:33,971:INFO:finalize_model() succesfully completed......................................
2023-03-14 23:13:34,098:INFO:Initializing predict_model()
2023-03-14 23:13:34,098:INFO:predict_model(estimator=VotingClassifier(estimators=[('lightgbm',
                              LGBMClassifier(bagging_fraction=0.5,
                                             bagging_freq=1,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.5, max_depth=-1,
                                             min_child_samples=11,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=250, n_jobs=-1,
                                             num_leaves=30, objective=None,
                                             ran...
                                                     criterion='entropy',
                                                     max_depth=9,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0,
                                                     min_impurity_split=None,
                                                     min_samples_leaf=6,
                                                     min_samples_split=10,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=230,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=42, verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, drift_report=False, raw_score=False, round=4, verbose=True, ml_usecase=MLUsecase.CLASSIFICATION, display=None, drift_kwargs=None)
2023-03-14 23:13:34,098:INFO:Checking exceptions
2023-03-14 23:13:34,099:INFO:Preloading libraries
2023-03-14 23:13:34,099:INFO:Preparing display monitor
2023-04-05 09:18:49,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-05 09:18:49,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-05 09:18:49,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-05 09:18:49,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-05 09:18:50,737:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-05 09:19:27,592:INFO:PyCaret ClassificationExperiment
2023-04-05 09:19:27,593:INFO:Logging name: clf-default-name
2023-04-05 09:19:27,593:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:19:27,593:INFO:version 3.0.0
2023-04-05 09:19:27,593:INFO:Initializing setup()
2023-04-05 09:19:27,593:INFO:self.USI: 450d
2023-04-05 09:19:27,593:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:19:27,593:INFO:Checking environment
2023-04-05 09:19:27,593:INFO:python_version: 3.9.16
2023-04-05 09:19:27,593:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:19:27,593:INFO:machine: AMD64
2023-04-05 09:19:27,593:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:19:27,593:INFO:Memory: svmem(total=17007173632, available=8010928128, percent=52.9, used=8996245504, free=8010928128)
2023-04-05 09:19:27,593:INFO:Physical Core: 6
2023-04-05 09:19:27,593:INFO:Logical Core: 12
2023-04-05 09:19:27,593:INFO:Checking libraries
2023-04-05 09:19:27,593:INFO:System:
2023-04-05 09:19:27,593:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:19:27,593:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:19:27,593:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:19:27,593:INFO:PyCaret required dependencies:
2023-04-05 09:19:27,593:INFO:                 pip: 22.3.1
2023-04-05 09:19:27,594:INFO:          setuptools: 60.10.0
2023-04-05 09:19:27,594:INFO:             pycaret: 3.0.0
2023-04-05 09:19:27,594:INFO:             IPython: 8.10.0
2023-04-05 09:19:27,594:INFO:          ipywidgets: 8.0.6
2023-04-05 09:19:27,594:INFO:                tqdm: 4.64.1
2023-04-05 09:19:27,594:INFO:               numpy: 1.23.5
2023-04-05 09:19:27,594:INFO:              pandas: 1.5.3
2023-04-05 09:19:27,594:INFO:              jinja2: 3.1.2
2023-04-05 09:19:27,594:INFO:               scipy: 1.9.1
2023-04-05 09:19:27,594:INFO:              joblib: 1.2.0
2023-04-05 09:19:27,594:INFO:             sklearn: 1.2.2
2023-04-05 09:19:27,594:INFO:                pyod: 1.0.9
2023-04-05 09:19:27,594:INFO:            imblearn: 0.10.1
2023-04-05 09:19:27,595:INFO:   category_encoders: 2.6.0
2023-04-05 09:19:27,595:INFO:            lightgbm: 3.3.5
2023-04-05 09:19:27,595:INFO:               numba: 0.56.4
2023-04-05 09:19:27,595:INFO:            requests: 2.28.1
2023-04-05 09:19:27,595:INFO:          matplotlib: 3.7.1
2023-04-05 09:19:27,595:INFO:          scikitplot: 0.3.7
2023-04-05 09:19:27,595:INFO:         yellowbrick: 1.5
2023-04-05 09:19:27,595:INFO:              plotly: 5.14.0
2023-04-05 09:19:27,595:INFO:             kaleido: 0.2.1
2023-04-05 09:19:27,595:INFO:         statsmodels: 0.13.5
2023-04-05 09:19:27,595:INFO:              sktime: 0.17.0
2023-04-05 09:19:27,595:INFO:               tbats: 1.1.2
2023-04-05 09:19:27,595:INFO:            pmdarima: 2.0.3
2023-04-05 09:19:27,595:INFO:              psutil: 5.9.0
2023-04-05 09:19:27,596:INFO:PyCaret optional dependencies:
2023-04-05 09:19:27,609:INFO:                shap: 0.41.0
2023-04-05 09:19:27,609:INFO:           interpret: 0.3.2
2023-04-05 09:19:27,609:INFO:                umap: Not installed
2023-04-05 09:19:27,609:INFO:    pandas_profiling: Not installed
2023-04-05 09:19:27,609:INFO:  explainerdashboard: Not installed
2023-04-05 09:19:27,609:INFO:             autoviz: Not installed
2023-04-05 09:19:27,609:INFO:           fairlearn: Not installed
2023-04-05 09:19:27,609:INFO:             xgboost: 1.7.4
2023-04-05 09:19:27,609:INFO:            catboost: Not installed
2023-04-05 09:19:27,609:INFO:              kmodes: Not installed
2023-04-05 09:19:27,609:INFO:             mlxtend: Not installed
2023-04-05 09:19:27,609:INFO:       statsforecast: Not installed
2023-04-05 09:19:27,609:INFO:        tune_sklearn: Not installed
2023-04-05 09:19:27,609:INFO:                 ray: Not installed
2023-04-05 09:19:27,609:INFO:            hyperopt: Not installed
2023-04-05 09:19:27,609:INFO:              optuna: Not installed
2023-04-05 09:19:27,610:INFO:               skopt: Not installed
2023-04-05 09:19:27,610:INFO:              mlflow: Not installed
2023-04-05 09:19:27,610:INFO:              gradio: Not installed
2023-04-05 09:19:27,610:INFO:             fastapi: Not installed
2023-04-05 09:19:27,610:INFO:             uvicorn: Not installed
2023-04-05 09:19:27,610:INFO:              m2cgen: Not installed
2023-04-05 09:19:27,610:INFO:           evidently: Not installed
2023-04-05 09:19:27,610:INFO:               fugue: Not installed
2023-04-05 09:19:27,610:INFO:           streamlit: Not installed
2023-04-05 09:19:27,610:INFO:             prophet: Not installed
2023-04-05 09:19:27,610:INFO:None
2023-04-05 09:19:27,610:INFO:Set up data.
2023-04-05 09:25:34,596:INFO:PyCaret ClassificationExperiment
2023-04-05 09:25:34,596:INFO:Logging name: clf-default-name
2023-04-05 09:25:34,596:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:25:34,596:INFO:version 3.0.0
2023-04-05 09:25:34,596:INFO:Initializing setup()
2023-04-05 09:25:34,596:INFO:self.USI: b75c
2023-04-05 09:25:34,596:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:25:34,597:INFO:Checking environment
2023-04-05 09:25:34,597:INFO:python_version: 3.9.16
2023-04-05 09:25:34,597:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:25:34,597:INFO:machine: AMD64
2023-04-05 09:25:34,597:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:25:34,597:INFO:Memory: svmem(total=17007173632, available=8105062400, percent=52.3, used=8902111232, free=8105062400)
2023-04-05 09:25:34,597:INFO:Physical Core: 6
2023-04-05 09:25:34,597:INFO:Logical Core: 12
2023-04-05 09:25:34,597:INFO:Checking libraries
2023-04-05 09:25:34,597:INFO:System:
2023-04-05 09:25:34,597:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:25:34,597:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:25:34,597:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:25:34,597:INFO:PyCaret required dependencies:
2023-04-05 09:25:34,597:INFO:                 pip: 22.3.1
2023-04-05 09:25:34,597:INFO:          setuptools: 60.10.0
2023-04-05 09:25:34,597:INFO:             pycaret: 3.0.0
2023-04-05 09:25:34,597:INFO:             IPython: 8.10.0
2023-04-05 09:25:34,597:INFO:          ipywidgets: 8.0.6
2023-04-05 09:25:34,597:INFO:                tqdm: 4.64.1
2023-04-05 09:25:34,598:INFO:               numpy: 1.23.5
2023-04-05 09:25:34,598:INFO:              pandas: 1.5.3
2023-04-05 09:25:34,598:INFO:              jinja2: 3.1.2
2023-04-05 09:25:34,598:INFO:               scipy: 1.9.1
2023-04-05 09:25:34,598:INFO:              joblib: 1.2.0
2023-04-05 09:25:34,598:INFO:             sklearn: 1.2.2
2023-04-05 09:25:34,598:INFO:                pyod: 1.0.9
2023-04-05 09:25:34,598:INFO:            imblearn: 0.10.1
2023-04-05 09:25:34,598:INFO:   category_encoders: 2.6.0
2023-04-05 09:25:34,598:INFO:            lightgbm: 3.3.5
2023-04-05 09:25:34,598:INFO:               numba: 0.56.4
2023-04-05 09:25:34,598:INFO:            requests: 2.28.1
2023-04-05 09:25:34,598:INFO:          matplotlib: 3.7.1
2023-04-05 09:25:34,598:INFO:          scikitplot: 0.3.7
2023-04-05 09:25:34,598:INFO:         yellowbrick: 1.5
2023-04-05 09:25:34,598:INFO:              plotly: 5.14.0
2023-04-05 09:25:34,598:INFO:             kaleido: 0.2.1
2023-04-05 09:25:34,598:INFO:         statsmodels: 0.13.5
2023-04-05 09:25:34,598:INFO:              sktime: 0.17.0
2023-04-05 09:25:34,598:INFO:               tbats: 1.1.2
2023-04-05 09:25:34,598:INFO:            pmdarima: 2.0.3
2023-04-05 09:25:34,598:INFO:              psutil: 5.9.0
2023-04-05 09:25:34,598:INFO:PyCaret optional dependencies:
2023-04-05 09:25:34,599:INFO:                shap: 0.41.0
2023-04-05 09:25:34,599:INFO:           interpret: 0.3.2
2023-04-05 09:25:34,599:INFO:                umap: Not installed
2023-04-05 09:25:34,599:INFO:    pandas_profiling: Not installed
2023-04-05 09:25:34,599:INFO:  explainerdashboard: Not installed
2023-04-05 09:25:34,599:INFO:             autoviz: Not installed
2023-04-05 09:25:34,599:INFO:           fairlearn: Not installed
2023-04-05 09:25:34,599:INFO:             xgboost: 1.7.4
2023-04-05 09:25:34,599:INFO:            catboost: Not installed
2023-04-05 09:25:34,599:INFO:              kmodes: Not installed
2023-04-05 09:25:34,599:INFO:             mlxtend: Not installed
2023-04-05 09:25:34,599:INFO:       statsforecast: Not installed
2023-04-05 09:25:34,599:INFO:        tune_sklearn: Not installed
2023-04-05 09:25:34,599:INFO:                 ray: Not installed
2023-04-05 09:25:34,599:INFO:            hyperopt: Not installed
2023-04-05 09:25:34,599:INFO:              optuna: Not installed
2023-04-05 09:25:34,599:INFO:               skopt: Not installed
2023-04-05 09:25:34,599:INFO:              mlflow: Not installed
2023-04-05 09:25:34,599:INFO:              gradio: Not installed
2023-04-05 09:25:34,599:INFO:             fastapi: Not installed
2023-04-05 09:25:34,599:INFO:             uvicorn: Not installed
2023-04-05 09:25:34,599:INFO:              m2cgen: Not installed
2023-04-05 09:25:34,599:INFO:           evidently: Not installed
2023-04-05 09:25:34,599:INFO:               fugue: Not installed
2023-04-05 09:25:34,600:INFO:           streamlit: Not installed
2023-04-05 09:25:34,600:INFO:             prophet: Not installed
2023-04-05 09:25:34,600:INFO:None
2023-04-05 09:25:34,600:INFO:Set up data.
2023-04-05 09:26:12,147:INFO:PyCaret ClassificationExperiment
2023-04-05 09:26:12,148:INFO:Logging name: clf-default-name
2023-04-05 09:26:12,148:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:26:12,148:INFO:version 3.0.0
2023-04-05 09:26:12,148:INFO:Initializing setup()
2023-04-05 09:26:12,148:INFO:self.USI: 131a
2023-04-05 09:26:12,148:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:26:12,148:INFO:Checking environment
2023-04-05 09:26:12,148:INFO:python_version: 3.9.16
2023-04-05 09:26:12,149:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:26:12,149:INFO:machine: AMD64
2023-04-05 09:26:12,149:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:26:12,149:INFO:Memory: svmem(total=17007173632, available=7864987648, percent=53.8, used=9142185984, free=7864987648)
2023-04-05 09:26:12,149:INFO:Physical Core: 6
2023-04-05 09:26:12,149:INFO:Logical Core: 12
2023-04-05 09:26:12,149:INFO:Checking libraries
2023-04-05 09:26:12,149:INFO:System:
2023-04-05 09:26:12,149:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:26:12,149:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:26:12,149:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:26:12,149:INFO:PyCaret required dependencies:
2023-04-05 09:26:12,149:INFO:                 pip: 22.3.1
2023-04-05 09:26:12,149:INFO:          setuptools: 60.10.0
2023-04-05 09:26:12,149:INFO:             pycaret: 3.0.0
2023-04-05 09:26:12,149:INFO:             IPython: 8.10.0
2023-04-05 09:26:12,149:INFO:          ipywidgets: 8.0.6
2023-04-05 09:26:12,150:INFO:                tqdm: 4.64.1
2023-04-05 09:26:12,150:INFO:               numpy: 1.23.5
2023-04-05 09:26:12,150:INFO:              pandas: 1.5.3
2023-04-05 09:26:12,150:INFO:              jinja2: 3.1.2
2023-04-05 09:26:12,150:INFO:               scipy: 1.9.1
2023-04-05 09:26:12,150:INFO:              joblib: 1.2.0
2023-04-05 09:26:12,150:INFO:             sklearn: 1.2.2
2023-04-05 09:26:12,150:INFO:                pyod: 1.0.9
2023-04-05 09:26:12,150:INFO:            imblearn: 0.10.1
2023-04-05 09:26:12,150:INFO:   category_encoders: 2.6.0
2023-04-05 09:26:12,150:INFO:            lightgbm: 3.3.5
2023-04-05 09:26:12,150:INFO:               numba: 0.56.4
2023-04-05 09:26:12,150:INFO:            requests: 2.28.1
2023-04-05 09:26:12,150:INFO:          matplotlib: 3.7.1
2023-04-05 09:26:12,150:INFO:          scikitplot: 0.3.7
2023-04-05 09:26:12,150:INFO:         yellowbrick: 1.5
2023-04-05 09:26:12,151:INFO:              plotly: 5.14.0
2023-04-05 09:26:12,151:INFO:             kaleido: 0.2.1
2023-04-05 09:26:12,151:INFO:         statsmodels: 0.13.5
2023-04-05 09:26:12,151:INFO:              sktime: 0.17.0
2023-04-05 09:26:12,151:INFO:               tbats: 1.1.2
2023-04-05 09:26:12,151:INFO:            pmdarima: 2.0.3
2023-04-05 09:26:12,151:INFO:              psutil: 5.9.0
2023-04-05 09:26:12,151:INFO:PyCaret optional dependencies:
2023-04-05 09:26:12,151:INFO:                shap: 0.41.0
2023-04-05 09:26:12,151:INFO:           interpret: 0.3.2
2023-04-05 09:26:12,151:INFO:                umap: Not installed
2023-04-05 09:26:12,151:INFO:    pandas_profiling: Not installed
2023-04-05 09:26:12,151:INFO:  explainerdashboard: Not installed
2023-04-05 09:26:12,151:INFO:             autoviz: Not installed
2023-04-05 09:26:12,151:INFO:           fairlearn: Not installed
2023-04-05 09:26:12,151:INFO:             xgboost: 1.7.4
2023-04-05 09:26:12,151:INFO:            catboost: Not installed
2023-04-05 09:26:12,151:INFO:              kmodes: Not installed
2023-04-05 09:26:12,151:INFO:             mlxtend: Not installed
2023-04-05 09:26:12,151:INFO:       statsforecast: Not installed
2023-04-05 09:26:12,151:INFO:        tune_sklearn: Not installed
2023-04-05 09:26:12,151:INFO:                 ray: Not installed
2023-04-05 09:26:12,151:INFO:            hyperopt: Not installed
2023-04-05 09:26:12,151:INFO:              optuna: Not installed
2023-04-05 09:26:12,151:INFO:               skopt: Not installed
2023-04-05 09:26:12,151:INFO:              mlflow: Not installed
2023-04-05 09:26:12,151:INFO:              gradio: Not installed
2023-04-05 09:26:12,151:INFO:             fastapi: Not installed
2023-04-05 09:26:12,151:INFO:             uvicorn: Not installed
2023-04-05 09:26:12,151:INFO:              m2cgen: Not installed
2023-04-05 09:26:12,151:INFO:           evidently: Not installed
2023-04-05 09:26:12,151:INFO:               fugue: Not installed
2023-04-05 09:26:12,151:INFO:           streamlit: Not installed
2023-04-05 09:26:12,151:INFO:             prophet: Not installed
2023-04-05 09:26:12,151:INFO:None
2023-04-05 09:26:12,153:INFO:Set up data.
2023-04-05 09:26:22,537:INFO:PyCaret ClassificationExperiment
2023-04-05 09:26:22,537:INFO:Logging name: clf-default-name
2023-04-05 09:26:22,537:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:26:22,537:INFO:version 3.0.0
2023-04-05 09:26:22,537:INFO:Initializing setup()
2023-04-05 09:26:22,537:INFO:self.USI: e33f
2023-04-05 09:26:22,538:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:26:22,538:INFO:Checking environment
2023-04-05 09:26:22,538:INFO:python_version: 3.9.16
2023-04-05 09:26:22,538:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:26:22,538:INFO:machine: AMD64
2023-04-05 09:26:22,538:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:26:22,538:INFO:Memory: svmem(total=17007173632, available=7616589824, percent=55.2, used=9390583808, free=7616589824)
2023-04-05 09:26:22,538:INFO:Physical Core: 6
2023-04-05 09:26:22,538:INFO:Logical Core: 12
2023-04-05 09:26:22,539:INFO:Checking libraries
2023-04-05 09:26:22,539:INFO:System:
2023-04-05 09:26:22,539:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:26:22,539:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:26:22,539:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:26:22,539:INFO:PyCaret required dependencies:
2023-04-05 09:26:22,539:INFO:                 pip: 22.3.1
2023-04-05 09:26:22,539:INFO:          setuptools: 60.10.0
2023-04-05 09:26:22,539:INFO:             pycaret: 3.0.0
2023-04-05 09:26:22,539:INFO:             IPython: 8.10.0
2023-04-05 09:26:22,539:INFO:          ipywidgets: 8.0.6
2023-04-05 09:26:22,539:INFO:                tqdm: 4.64.1
2023-04-05 09:26:22,539:INFO:               numpy: 1.23.5
2023-04-05 09:26:22,539:INFO:              pandas: 1.5.3
2023-04-05 09:26:22,539:INFO:              jinja2: 3.1.2
2023-04-05 09:26:22,540:INFO:               scipy: 1.9.1
2023-04-05 09:26:22,540:INFO:              joblib: 1.2.0
2023-04-05 09:26:22,540:INFO:             sklearn: 1.2.2
2023-04-05 09:26:22,540:INFO:                pyod: 1.0.9
2023-04-05 09:26:22,540:INFO:            imblearn: 0.10.1
2023-04-05 09:26:22,540:INFO:   category_encoders: 2.6.0
2023-04-05 09:26:22,540:INFO:            lightgbm: 3.3.5
2023-04-05 09:26:22,540:INFO:               numba: 0.56.4
2023-04-05 09:26:22,540:INFO:            requests: 2.28.1
2023-04-05 09:26:22,540:INFO:          matplotlib: 3.7.1
2023-04-05 09:26:22,540:INFO:          scikitplot: 0.3.7
2023-04-05 09:26:22,540:INFO:         yellowbrick: 1.5
2023-04-05 09:26:22,540:INFO:              plotly: 5.14.0
2023-04-05 09:26:22,540:INFO:             kaleido: 0.2.1
2023-04-05 09:26:22,540:INFO:         statsmodels: 0.13.5
2023-04-05 09:26:22,540:INFO:              sktime: 0.17.0
2023-04-05 09:26:22,540:INFO:               tbats: 1.1.2
2023-04-05 09:26:22,541:INFO:            pmdarima: 2.0.3
2023-04-05 09:26:22,541:INFO:              psutil: 5.9.0
2023-04-05 09:26:22,541:INFO:PyCaret optional dependencies:
2023-04-05 09:26:22,541:INFO:                shap: 0.41.0
2023-04-05 09:26:22,541:INFO:           interpret: 0.3.2
2023-04-05 09:26:22,541:INFO:                umap: Not installed
2023-04-05 09:26:22,541:INFO:    pandas_profiling: Not installed
2023-04-05 09:26:22,541:INFO:  explainerdashboard: Not installed
2023-04-05 09:26:22,541:INFO:             autoviz: Not installed
2023-04-05 09:26:22,541:INFO:           fairlearn: Not installed
2023-04-05 09:26:22,541:INFO:             xgboost: 1.7.4
2023-04-05 09:26:22,541:INFO:            catboost: Not installed
2023-04-05 09:26:22,541:INFO:              kmodes: Not installed
2023-04-05 09:26:22,541:INFO:             mlxtend: Not installed
2023-04-05 09:26:22,541:INFO:       statsforecast: Not installed
2023-04-05 09:26:22,541:INFO:        tune_sklearn: Not installed
2023-04-05 09:26:22,542:INFO:                 ray: Not installed
2023-04-05 09:26:22,542:INFO:            hyperopt: Not installed
2023-04-05 09:26:22,542:INFO:              optuna: Not installed
2023-04-05 09:26:22,542:INFO:               skopt: Not installed
2023-04-05 09:26:22,542:INFO:              mlflow: Not installed
2023-04-05 09:26:22,542:INFO:              gradio: Not installed
2023-04-05 09:26:22,542:INFO:             fastapi: Not installed
2023-04-05 09:26:22,542:INFO:             uvicorn: Not installed
2023-04-05 09:26:22,542:INFO:              m2cgen: Not installed
2023-04-05 09:26:22,542:INFO:           evidently: Not installed
2023-04-05 09:26:22,542:INFO:               fugue: Not installed
2023-04-05 09:26:22,542:INFO:           streamlit: Not installed
2023-04-05 09:26:22,542:INFO:             prophet: Not installed
2023-04-05 09:26:22,542:INFO:None
2023-04-05 09:26:22,542:INFO:Set up data.
2023-04-05 09:27:38,173:INFO:PyCaret ClassificationExperiment
2023-04-05 09:27:38,174:INFO:Logging name: clf-default-name
2023-04-05 09:27:38,174:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:27:38,174:INFO:version 3.0.0
2023-04-05 09:27:38,174:INFO:Initializing setup()
2023-04-05 09:27:38,174:INFO:self.USI: ce62
2023-04-05 09:27:38,174:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:27:38,174:INFO:Checking environment
2023-04-05 09:27:38,174:INFO:python_version: 3.9.16
2023-04-05 09:27:38,174:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:27:38,174:INFO:machine: AMD64
2023-04-05 09:27:38,174:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:27:38,174:INFO:Memory: svmem(total=17007173632, available=7202193408, percent=57.7, used=9804980224, free=7202193408)
2023-04-05 09:27:38,174:INFO:Physical Core: 6
2023-04-05 09:27:38,174:INFO:Logical Core: 12
2023-04-05 09:27:38,174:INFO:Checking libraries
2023-04-05 09:27:38,175:INFO:System:
2023-04-05 09:27:38,175:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:27:38,175:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:27:38,175:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:27:38,175:INFO:PyCaret required dependencies:
2023-04-05 09:27:38,175:INFO:                 pip: 22.3.1
2023-04-05 09:27:38,175:INFO:          setuptools: 60.10.0
2023-04-05 09:27:38,175:INFO:             pycaret: 3.0.0
2023-04-05 09:27:38,175:INFO:             IPython: 8.10.0
2023-04-05 09:27:38,175:INFO:          ipywidgets: 8.0.6
2023-04-05 09:27:38,175:INFO:                tqdm: 4.64.1
2023-04-05 09:27:38,175:INFO:               numpy: 1.23.5
2023-04-05 09:27:38,175:INFO:              pandas: 1.5.3
2023-04-05 09:27:38,175:INFO:              jinja2: 3.1.2
2023-04-05 09:27:38,175:INFO:               scipy: 1.9.1
2023-04-05 09:27:38,175:INFO:              joblib: 1.2.0
2023-04-05 09:27:38,175:INFO:             sklearn: 1.2.2
2023-04-05 09:27:38,175:INFO:                pyod: 1.0.9
2023-04-05 09:27:38,176:INFO:            imblearn: 0.10.1
2023-04-05 09:27:38,176:INFO:   category_encoders: 2.6.0
2023-04-05 09:27:38,176:INFO:            lightgbm: 3.3.5
2023-04-05 09:27:38,176:INFO:               numba: 0.56.4
2023-04-05 09:27:38,176:INFO:            requests: 2.28.1
2023-04-05 09:27:38,176:INFO:          matplotlib: 3.7.1
2023-04-05 09:27:38,176:INFO:          scikitplot: 0.3.7
2023-04-05 09:27:38,176:INFO:         yellowbrick: 1.5
2023-04-05 09:27:38,176:INFO:              plotly: 5.14.0
2023-04-05 09:27:38,176:INFO:             kaleido: 0.2.1
2023-04-05 09:27:38,176:INFO:         statsmodels: 0.13.5
2023-04-05 09:27:38,176:INFO:              sktime: 0.17.0
2023-04-05 09:27:38,176:INFO:               tbats: 1.1.2
2023-04-05 09:27:38,176:INFO:            pmdarima: 2.0.3
2023-04-05 09:27:38,176:INFO:              psutil: 5.9.0
2023-04-05 09:27:38,176:INFO:PyCaret optional dependencies:
2023-04-05 09:27:38,176:INFO:                shap: 0.41.0
2023-04-05 09:27:38,176:INFO:           interpret: 0.3.2
2023-04-05 09:27:38,176:INFO:                umap: Not installed
2023-04-05 09:27:38,176:INFO:    pandas_profiling: Not installed
2023-04-05 09:27:38,176:INFO:  explainerdashboard: Not installed
2023-04-05 09:27:38,176:INFO:             autoviz: Not installed
2023-04-05 09:27:38,176:INFO:           fairlearn: Not installed
2023-04-05 09:27:38,177:INFO:             xgboost: 1.7.4
2023-04-05 09:27:38,177:INFO:            catboost: Not installed
2023-04-05 09:27:38,177:INFO:              kmodes: Not installed
2023-04-05 09:27:38,177:INFO:             mlxtend: Not installed
2023-04-05 09:27:38,177:INFO:       statsforecast: Not installed
2023-04-05 09:27:38,177:INFO:        tune_sklearn: Not installed
2023-04-05 09:27:38,177:INFO:                 ray: Not installed
2023-04-05 09:27:38,177:INFO:            hyperopt: Not installed
2023-04-05 09:27:38,177:INFO:              optuna: Not installed
2023-04-05 09:27:38,177:INFO:               skopt: Not installed
2023-04-05 09:27:38,177:INFO:              mlflow: Not installed
2023-04-05 09:27:38,177:INFO:              gradio: Not installed
2023-04-05 09:27:38,177:INFO:             fastapi: Not installed
2023-04-05 09:27:38,177:INFO:             uvicorn: Not installed
2023-04-05 09:27:38,177:INFO:              m2cgen: Not installed
2023-04-05 09:27:38,177:INFO:           evidently: Not installed
2023-04-05 09:27:38,177:INFO:               fugue: Not installed
2023-04-05 09:27:38,177:INFO:           streamlit: Not installed
2023-04-05 09:27:38,177:INFO:             prophet: Not installed
2023-04-05 09:27:38,177:INFO:None
2023-04-05 09:27:38,177:INFO:Set up data.
2023-04-05 09:27:40,968:INFO:Set up train/test split.
2023-04-05 09:38:34,864:INFO:PyCaret ClassificationExperiment
2023-04-05 09:38:34,864:INFO:Logging name: clf-default-name
2023-04-05 09:38:34,864:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:38:34,864:INFO:version 3.0.0
2023-04-05 09:38:34,864:INFO:Initializing setup()
2023-04-05 09:38:34,864:INFO:self.USI: 5994
2023-04-05 09:38:34,864:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:38:34,864:INFO:Checking environment
2023-04-05 09:38:34,864:INFO:python_version: 3.9.16
2023-04-05 09:38:34,864:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:38:34,864:INFO:machine: AMD64
2023-04-05 09:38:34,864:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:38:34,865:INFO:Memory: svmem(total=17007173632, available=7849439232, percent=53.8, used=9157734400, free=7849439232)
2023-04-05 09:38:34,865:INFO:Physical Core: 6
2023-04-05 09:38:34,865:INFO:Logical Core: 12
2023-04-05 09:38:34,865:INFO:Checking libraries
2023-04-05 09:38:34,865:INFO:System:
2023-04-05 09:38:34,865:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:38:34,865:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:38:34,865:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:38:34,865:INFO:PyCaret required dependencies:
2023-04-05 09:38:34,865:INFO:                 pip: 22.3.1
2023-04-05 09:38:34,865:INFO:          setuptools: 60.10.0
2023-04-05 09:38:34,865:INFO:             pycaret: 3.0.0
2023-04-05 09:38:34,865:INFO:             IPython: 8.10.0
2023-04-05 09:38:34,865:INFO:          ipywidgets: 8.0.6
2023-04-05 09:38:34,865:INFO:                tqdm: 4.64.1
2023-04-05 09:38:34,865:INFO:               numpy: 1.23.5
2023-04-05 09:38:34,865:INFO:              pandas: 1.5.3
2023-04-05 09:38:34,865:INFO:              jinja2: 3.1.2
2023-04-05 09:38:34,865:INFO:               scipy: 1.9.1
2023-04-05 09:38:34,865:INFO:              joblib: 1.2.0
2023-04-05 09:38:34,865:INFO:             sklearn: 1.2.2
2023-04-05 09:38:34,865:INFO:                pyod: 1.0.9
2023-04-05 09:38:34,866:INFO:            imblearn: 0.10.1
2023-04-05 09:38:34,866:INFO:   category_encoders: 2.6.0
2023-04-05 09:38:34,866:INFO:            lightgbm: 3.3.5
2023-04-05 09:38:34,866:INFO:               numba: 0.56.4
2023-04-05 09:38:34,866:INFO:            requests: 2.28.1
2023-04-05 09:38:34,866:INFO:          matplotlib: 3.7.1
2023-04-05 09:38:34,866:INFO:          scikitplot: 0.3.7
2023-04-05 09:38:34,866:INFO:         yellowbrick: 1.5
2023-04-05 09:38:34,866:INFO:              plotly: 5.14.0
2023-04-05 09:38:34,866:INFO:             kaleido: 0.2.1
2023-04-05 09:38:34,866:INFO:         statsmodels: 0.13.5
2023-04-05 09:38:34,866:INFO:              sktime: 0.17.0
2023-04-05 09:38:34,866:INFO:               tbats: 1.1.2
2023-04-05 09:38:34,866:INFO:            pmdarima: 2.0.3
2023-04-05 09:38:34,866:INFO:              psutil: 5.9.0
2023-04-05 09:38:34,866:INFO:PyCaret optional dependencies:
2023-04-05 09:38:34,866:INFO:                shap: 0.41.0
2023-04-05 09:38:34,867:INFO:           interpret: 0.3.2
2023-04-05 09:38:34,867:INFO:                umap: Not installed
2023-04-05 09:38:34,867:INFO:    pandas_profiling: Not installed
2023-04-05 09:38:34,867:INFO:  explainerdashboard: Not installed
2023-04-05 09:38:34,867:INFO:             autoviz: Not installed
2023-04-05 09:38:34,867:INFO:           fairlearn: Not installed
2023-04-05 09:38:34,867:INFO:             xgboost: 1.7.4
2023-04-05 09:38:34,867:INFO:            catboost: Not installed
2023-04-05 09:38:34,867:INFO:              kmodes: Not installed
2023-04-05 09:38:34,867:INFO:             mlxtend: Not installed
2023-04-05 09:38:34,867:INFO:       statsforecast: Not installed
2023-04-05 09:38:34,867:INFO:        tune_sklearn: Not installed
2023-04-05 09:38:34,867:INFO:                 ray: Not installed
2023-04-05 09:38:34,867:INFO:            hyperopt: Not installed
2023-04-05 09:38:34,867:INFO:              optuna: Not installed
2023-04-05 09:38:34,868:INFO:               skopt: Not installed
2023-04-05 09:38:34,868:INFO:              mlflow: Not installed
2023-04-05 09:38:34,868:INFO:              gradio: Not installed
2023-04-05 09:38:34,868:INFO:             fastapi: Not installed
2023-04-05 09:38:34,868:INFO:             uvicorn: Not installed
2023-04-05 09:38:34,868:INFO:              m2cgen: Not installed
2023-04-05 09:38:34,868:INFO:           evidently: Not installed
2023-04-05 09:38:34,868:INFO:               fugue: Not installed
2023-04-05 09:38:34,868:INFO:           streamlit: Not installed
2023-04-05 09:38:34,868:INFO:             prophet: Not installed
2023-04-05 09:38:34,868:INFO:None
2023-04-05 09:38:34,868:INFO:Set up data.
2023-04-05 09:44:32,815:INFO:PyCaret ClassificationExperiment
2023-04-05 09:44:32,816:INFO:Logging name: clf-default-name
2023-04-05 09:44:32,816:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:44:32,816:INFO:version 3.0.0
2023-04-05 09:44:32,816:INFO:Initializing setup()
2023-04-05 09:44:32,817:INFO:self.USI: 89fd
2023-04-05 09:44:32,817:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:44:32,817:INFO:Checking environment
2023-04-05 09:44:32,817:INFO:python_version: 3.9.16
2023-04-05 09:44:32,817:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:44:32,817:INFO:machine: AMD64
2023-04-05 09:44:32,817:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:44:32,817:INFO:Memory: svmem(total=17007173632, available=6397943808, percent=62.4, used=10609229824, free=6397943808)
2023-04-05 09:44:32,817:INFO:Physical Core: 6
2023-04-05 09:44:32,817:INFO:Logical Core: 12
2023-04-05 09:44:32,817:INFO:Checking libraries
2023-04-05 09:44:32,817:INFO:System:
2023-04-05 09:44:32,817:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:44:32,817:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:44:32,817:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:44:32,817:INFO:PyCaret required dependencies:
2023-04-05 09:44:32,817:INFO:                 pip: 22.3.1
2023-04-05 09:44:32,817:INFO:          setuptools: 60.10.0
2023-04-05 09:44:32,817:INFO:             pycaret: 3.0.0
2023-04-05 09:44:32,817:INFO:             IPython: 8.10.0
2023-04-05 09:44:32,818:INFO:          ipywidgets: 8.0.6
2023-04-05 09:44:32,818:INFO:                tqdm: 4.64.1
2023-04-05 09:44:32,818:INFO:               numpy: 1.23.5
2023-04-05 09:44:32,818:INFO:              pandas: 1.5.3
2023-04-05 09:44:32,818:INFO:              jinja2: 3.1.2
2023-04-05 09:44:32,818:INFO:               scipy: 1.9.1
2023-04-05 09:44:32,818:INFO:              joblib: 1.2.0
2023-04-05 09:44:32,818:INFO:             sklearn: 1.2.2
2023-04-05 09:44:32,818:INFO:                pyod: 1.0.9
2023-04-05 09:44:32,818:INFO:            imblearn: 0.10.1
2023-04-05 09:44:32,818:INFO:   category_encoders: 2.6.0
2023-04-05 09:44:32,818:INFO:            lightgbm: 3.3.5
2023-04-05 09:44:32,818:INFO:               numba: 0.56.4
2023-04-05 09:44:32,818:INFO:            requests: 2.28.1
2023-04-05 09:44:32,818:INFO:          matplotlib: 3.7.1
2023-04-05 09:44:32,818:INFO:          scikitplot: 0.3.7
2023-04-05 09:44:32,818:INFO:         yellowbrick: 1.5
2023-04-05 09:44:32,819:INFO:              plotly: 5.14.0
2023-04-05 09:44:32,819:INFO:             kaleido: 0.2.1
2023-04-05 09:44:32,819:INFO:         statsmodels: 0.13.5
2023-04-05 09:44:32,819:INFO:              sktime: 0.17.0
2023-04-05 09:44:32,819:INFO:               tbats: 1.1.2
2023-04-05 09:44:32,819:INFO:            pmdarima: 2.0.3
2023-04-05 09:44:32,819:INFO:              psutil: 5.9.0
2023-04-05 09:44:32,819:INFO:PyCaret optional dependencies:
2023-04-05 09:44:32,819:INFO:                shap: 0.41.0
2023-04-05 09:44:32,819:INFO:           interpret: 0.3.2
2023-04-05 09:44:32,819:INFO:                umap: Not installed
2023-04-05 09:44:32,819:INFO:    pandas_profiling: Not installed
2023-04-05 09:44:32,819:INFO:  explainerdashboard: Not installed
2023-04-05 09:44:32,819:INFO:             autoviz: Not installed
2023-04-05 09:44:32,819:INFO:           fairlearn: Not installed
2023-04-05 09:44:32,819:INFO:             xgboost: 1.7.4
2023-04-05 09:44:32,819:INFO:            catboost: Not installed
2023-04-05 09:44:32,820:INFO:              kmodes: Not installed
2023-04-05 09:44:32,820:INFO:             mlxtend: Not installed
2023-04-05 09:44:32,820:INFO:       statsforecast: Not installed
2023-04-05 09:44:32,820:INFO:        tune_sklearn: Not installed
2023-04-05 09:44:32,820:INFO:                 ray: Not installed
2023-04-05 09:44:32,820:INFO:            hyperopt: Not installed
2023-04-05 09:44:32,820:INFO:              optuna: Not installed
2023-04-05 09:44:32,820:INFO:               skopt: Not installed
2023-04-05 09:44:32,820:INFO:              mlflow: Not installed
2023-04-05 09:44:32,820:INFO:              gradio: Not installed
2023-04-05 09:44:32,820:INFO:             fastapi: Not installed
2023-04-05 09:44:32,820:INFO:             uvicorn: Not installed
2023-04-05 09:44:32,820:INFO:              m2cgen: Not installed
2023-04-05 09:44:32,820:INFO:           evidently: Not installed
2023-04-05 09:44:32,820:INFO:               fugue: Not installed
2023-04-05 09:44:32,820:INFO:           streamlit: Not installed
2023-04-05 09:44:32,821:INFO:             prophet: Not installed
2023-04-05 09:44:32,821:INFO:None
2023-04-05 09:44:32,821:INFO:Set up data.
2023-04-05 09:46:01,211:INFO:PyCaret ClassificationExperiment
2023-04-05 09:46:01,211:INFO:Logging name: clf-default-name
2023-04-05 09:46:01,211:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:46:01,211:INFO:version 3.0.0
2023-04-05 09:46:01,211:INFO:Initializing setup()
2023-04-05 09:46:01,211:INFO:self.USI: f4c2
2023-04-05 09:46:01,211:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:46:01,211:INFO:Checking environment
2023-04-05 09:46:01,211:INFO:python_version: 3.9.16
2023-04-05 09:46:01,211:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:46:01,213:INFO:machine: AMD64
2023-04-05 09:46:01,213:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:46:01,213:INFO:Memory: svmem(total=17007173632, available=5354106880, percent=68.5, used=11653066752, free=5354106880)
2023-04-05 09:46:01,213:INFO:Physical Core: 6
2023-04-05 09:46:01,213:INFO:Logical Core: 12
2023-04-05 09:46:01,213:INFO:Checking libraries
2023-04-05 09:46:01,213:INFO:System:
2023-04-05 09:46:01,213:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:46:01,213:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:46:01,213:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:46:01,213:INFO:PyCaret required dependencies:
2023-04-05 09:46:01,214:INFO:                 pip: 22.3.1
2023-04-05 09:46:01,214:INFO:          setuptools: 60.10.0
2023-04-05 09:46:01,214:INFO:             pycaret: 3.0.0
2023-04-05 09:46:01,214:INFO:             IPython: 8.10.0
2023-04-05 09:46:01,214:INFO:          ipywidgets: 8.0.6
2023-04-05 09:46:01,214:INFO:                tqdm: 4.64.1
2023-04-05 09:46:01,214:INFO:               numpy: 1.23.5
2023-04-05 09:46:01,214:INFO:              pandas: 1.5.3
2023-04-05 09:46:01,214:INFO:              jinja2: 3.1.2
2023-04-05 09:46:01,214:INFO:               scipy: 1.9.1
2023-04-05 09:46:01,214:INFO:              joblib: 1.2.0
2023-04-05 09:46:01,214:INFO:             sklearn: 1.2.2
2023-04-05 09:46:01,214:INFO:                pyod: 1.0.9
2023-04-05 09:46:01,214:INFO:            imblearn: 0.10.1
2023-04-05 09:46:01,214:INFO:   category_encoders: 2.6.0
2023-04-05 09:46:01,214:INFO:            lightgbm: 3.3.5
2023-04-05 09:46:01,214:INFO:               numba: 0.56.4
2023-04-05 09:46:01,214:INFO:            requests: 2.28.1
2023-04-05 09:46:01,214:INFO:          matplotlib: 3.7.1
2023-04-05 09:46:01,214:INFO:          scikitplot: 0.3.7
2023-04-05 09:46:01,214:INFO:         yellowbrick: 1.5
2023-04-05 09:46:01,215:INFO:              plotly: 5.14.0
2023-04-05 09:46:01,215:INFO:             kaleido: 0.2.1
2023-04-05 09:46:01,215:INFO:         statsmodels: 0.13.5
2023-04-05 09:46:01,215:INFO:              sktime: 0.17.0
2023-04-05 09:46:01,215:INFO:               tbats: 1.1.2
2023-04-05 09:46:01,215:INFO:            pmdarima: 2.0.3
2023-04-05 09:46:01,215:INFO:              psutil: 5.9.0
2023-04-05 09:46:01,215:INFO:PyCaret optional dependencies:
2023-04-05 09:46:01,215:INFO:                shap: 0.41.0
2023-04-05 09:46:01,215:INFO:           interpret: 0.3.2
2023-04-05 09:46:01,215:INFO:                umap: Not installed
2023-04-05 09:46:01,215:INFO:    pandas_profiling: Not installed
2023-04-05 09:46:01,215:INFO:  explainerdashboard: Not installed
2023-04-05 09:46:01,215:INFO:             autoviz: Not installed
2023-04-05 09:46:01,215:INFO:           fairlearn: Not installed
2023-04-05 09:46:01,215:INFO:             xgboost: 1.7.4
2023-04-05 09:46:01,215:INFO:            catboost: Not installed
2023-04-05 09:46:01,215:INFO:              kmodes: Not installed
2023-04-05 09:46:01,216:INFO:             mlxtend: Not installed
2023-04-05 09:46:01,216:INFO:       statsforecast: Not installed
2023-04-05 09:46:01,216:INFO:        tune_sklearn: Not installed
2023-04-05 09:46:01,216:INFO:                 ray: Not installed
2023-04-05 09:46:01,216:INFO:            hyperopt: Not installed
2023-04-05 09:46:01,216:INFO:              optuna: Not installed
2023-04-05 09:46:01,216:INFO:               skopt: Not installed
2023-04-05 09:46:01,216:INFO:              mlflow: Not installed
2023-04-05 09:46:01,216:INFO:              gradio: Not installed
2023-04-05 09:46:01,216:INFO:             fastapi: Not installed
2023-04-05 09:46:01,216:INFO:             uvicorn: Not installed
2023-04-05 09:46:01,216:INFO:              m2cgen: Not installed
2023-04-05 09:46:01,216:INFO:           evidently: Not installed
2023-04-05 09:46:01,216:INFO:               fugue: Not installed
2023-04-05 09:46:01,216:INFO:           streamlit: Not installed
2023-04-05 09:46:01,216:INFO:             prophet: Not installed
2023-04-05 09:46:01,216:INFO:None
2023-04-05 09:46:01,216:INFO:Set up data.
2023-04-05 09:46:03,504:INFO:Set up train/test split.
2023-04-05 09:47:00,529:INFO:PyCaret ClassificationExperiment
2023-04-05 09:47:00,529:INFO:Logging name: clf-default-name
2023-04-05 09:47:00,529:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:47:00,529:INFO:version 3.0.0
2023-04-05 09:47:00,529:INFO:Initializing setup()
2023-04-05 09:47:00,529:INFO:self.USI: 4b49
2023-04-05 09:47:00,530:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:47:00,530:INFO:Checking environment
2023-04-05 09:47:00,530:INFO:python_version: 3.9.16
2023-04-05 09:47:00,530:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:47:00,530:INFO:machine: AMD64
2023-04-05 09:47:00,530:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:47:00,530:INFO:Memory: svmem(total=17007173632, available=4830580736, percent=71.6, used=12176592896, free=4830580736)
2023-04-05 09:47:00,530:INFO:Physical Core: 6
2023-04-05 09:47:00,530:INFO:Logical Core: 12
2023-04-05 09:47:00,530:INFO:Checking libraries
2023-04-05 09:47:00,530:INFO:System:
2023-04-05 09:47:00,531:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:47:00,531:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:47:00,531:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:47:00,531:INFO:PyCaret required dependencies:
2023-04-05 09:47:00,531:INFO:                 pip: 22.3.1
2023-04-05 09:47:00,531:INFO:          setuptools: 60.10.0
2023-04-05 09:47:00,531:INFO:             pycaret: 3.0.0
2023-04-05 09:47:00,531:INFO:             IPython: 8.10.0
2023-04-05 09:47:00,531:INFO:          ipywidgets: 8.0.6
2023-04-05 09:47:00,531:INFO:                tqdm: 4.64.1
2023-04-05 09:47:00,531:INFO:               numpy: 1.23.5
2023-04-05 09:47:00,531:INFO:              pandas: 1.5.3
2023-04-05 09:47:00,531:INFO:              jinja2: 3.1.2
2023-04-05 09:47:00,531:INFO:               scipy: 1.9.1
2023-04-05 09:47:00,531:INFO:              joblib: 1.2.0
2023-04-05 09:47:00,531:INFO:             sklearn: 1.2.2
2023-04-05 09:47:00,531:INFO:                pyod: 1.0.9
2023-04-05 09:47:00,531:INFO:            imblearn: 0.10.1
2023-04-05 09:47:00,531:INFO:   category_encoders: 2.6.0
2023-04-05 09:47:00,531:INFO:            lightgbm: 3.3.5
2023-04-05 09:47:00,531:INFO:               numba: 0.56.4
2023-04-05 09:47:00,531:INFO:            requests: 2.28.1
2023-04-05 09:47:00,531:INFO:          matplotlib: 3.7.1
2023-04-05 09:47:00,531:INFO:          scikitplot: 0.3.7
2023-04-05 09:47:00,531:INFO:         yellowbrick: 1.5
2023-04-05 09:47:00,531:INFO:              plotly: 5.14.0
2023-04-05 09:47:00,531:INFO:             kaleido: 0.2.1
2023-04-05 09:47:00,531:INFO:         statsmodels: 0.13.5
2023-04-05 09:47:00,531:INFO:              sktime: 0.17.0
2023-04-05 09:47:00,531:INFO:               tbats: 1.1.2
2023-04-05 09:47:00,531:INFO:            pmdarima: 2.0.3
2023-04-05 09:47:00,531:INFO:              psutil: 5.9.0
2023-04-05 09:47:00,531:INFO:PyCaret optional dependencies:
2023-04-05 09:47:00,531:INFO:                shap: 0.41.0
2023-04-05 09:47:00,531:INFO:           interpret: 0.3.2
2023-04-05 09:47:00,531:INFO:                umap: Not installed
2023-04-05 09:47:00,531:INFO:    pandas_profiling: Not installed
2023-04-05 09:47:00,531:INFO:  explainerdashboard: Not installed
2023-04-05 09:47:00,531:INFO:             autoviz: Not installed
2023-04-05 09:47:00,531:INFO:           fairlearn: Not installed
2023-04-05 09:47:00,531:INFO:             xgboost: 1.7.4
2023-04-05 09:47:00,531:INFO:            catboost: Not installed
2023-04-05 09:47:00,533:INFO:              kmodes: Not installed
2023-04-05 09:47:00,533:INFO:             mlxtend: Not installed
2023-04-05 09:47:00,533:INFO:       statsforecast: Not installed
2023-04-05 09:47:00,533:INFO:        tune_sklearn: Not installed
2023-04-05 09:47:00,533:INFO:                 ray: Not installed
2023-04-05 09:47:00,533:INFO:            hyperopt: Not installed
2023-04-05 09:47:00,533:INFO:              optuna: Not installed
2023-04-05 09:47:00,533:INFO:               skopt: Not installed
2023-04-05 09:47:00,533:INFO:              mlflow: Not installed
2023-04-05 09:47:00,533:INFO:              gradio: Not installed
2023-04-05 09:47:00,533:INFO:             fastapi: Not installed
2023-04-05 09:47:00,533:INFO:             uvicorn: Not installed
2023-04-05 09:47:00,533:INFO:              m2cgen: Not installed
2023-04-05 09:47:00,534:INFO:           evidently: Not installed
2023-04-05 09:47:00,534:INFO:               fugue: Not installed
2023-04-05 09:47:00,534:INFO:           streamlit: Not installed
2023-04-05 09:47:00,534:INFO:             prophet: Not installed
2023-04-05 09:47:00,534:INFO:None
2023-04-05 09:47:00,534:INFO:Set up data.
2023-04-05 09:47:03,333:INFO:Set up train/test split.
2023-04-05 09:48:23,731:INFO:PyCaret ClassificationExperiment
2023-04-05 09:48:23,731:INFO:Logging name: clf-default-name
2023-04-05 09:48:23,731:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 09:48:23,731:INFO:version 3.0.0
2023-04-05 09:48:23,731:INFO:Initializing setup()
2023-04-05 09:48:23,731:INFO:self.USI: 854d
2023-04-05 09:48:23,731:INFO:self._variable_keys: {'gpu_n_jobs_param', 'memory', 'exp_name_log', 'logging_param', 'X', 'y_train', '_ml_usecase', 'fold_generator', 'n_jobs_param', 'X_train', 'target_param', '_available_plots', 'y', 'X_test', 'USI', 'pipeline', 'fold_groups_param', 'gpu_param', 'idx', 'data', 'log_plots_param', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'y_test', 'fold_shuffle_param', 'exp_id'}
2023-04-05 09:48:23,732:INFO:Checking environment
2023-04-05 09:48:23,732:INFO:python_version: 3.9.16
2023-04-05 09:48:23,732:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 09:48:23,732:INFO:machine: AMD64
2023-04-05 09:48:23,732:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 09:48:23,732:INFO:Memory: svmem(total=17007173632, available=5958995968, percent=65.0, used=11048177664, free=5958995968)
2023-04-05 09:48:23,732:INFO:Physical Core: 6
2023-04-05 09:48:23,732:INFO:Logical Core: 12
2023-04-05 09:48:23,732:INFO:Checking libraries
2023-04-05 09:48:23,732:INFO:System:
2023-04-05 09:48:23,732:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 09:48:23,732:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 09:48:23,732:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 09:48:23,732:INFO:PyCaret required dependencies:
2023-04-05 09:48:23,732:INFO:                 pip: 22.3.1
2023-04-05 09:48:23,732:INFO:          setuptools: 60.10.0
2023-04-05 09:48:23,732:INFO:             pycaret: 3.0.0
2023-04-05 09:48:23,733:INFO:             IPython: 8.10.0
2023-04-05 09:48:23,733:INFO:          ipywidgets: 8.0.6
2023-04-05 09:48:23,733:INFO:                tqdm: 4.64.1
2023-04-05 09:48:23,733:INFO:               numpy: 1.23.5
2023-04-05 09:48:23,733:INFO:              pandas: 1.5.3
2023-04-05 09:48:23,733:INFO:              jinja2: 3.1.2
2023-04-05 09:48:23,733:INFO:               scipy: 1.9.1
2023-04-05 09:48:23,733:INFO:              joblib: 1.2.0
2023-04-05 09:48:23,733:INFO:             sklearn: 1.2.2
2023-04-05 09:48:23,733:INFO:                pyod: 1.0.9
2023-04-05 09:48:23,733:INFO:            imblearn: 0.10.1
2023-04-05 09:48:23,733:INFO:   category_encoders: 2.6.0
2023-04-05 09:48:23,733:INFO:            lightgbm: 3.3.5
2023-04-05 09:48:23,733:INFO:               numba: 0.56.4
2023-04-05 09:48:23,733:INFO:            requests: 2.28.1
2023-04-05 09:48:23,734:INFO:          matplotlib: 3.7.1
2023-04-05 09:48:23,734:INFO:          scikitplot: 0.3.7
2023-04-05 09:48:23,734:INFO:         yellowbrick: 1.5
2023-04-05 09:48:23,734:INFO:              plotly: 5.14.0
2023-04-05 09:48:23,734:INFO:             kaleido: 0.2.1
2023-04-05 09:48:23,734:INFO:         statsmodels: 0.13.5
2023-04-05 09:48:23,734:INFO:              sktime: 0.17.0
2023-04-05 09:48:23,734:INFO:               tbats: 1.1.2
2023-04-05 09:48:23,734:INFO:            pmdarima: 2.0.3
2023-04-05 09:48:23,735:INFO:              psutil: 5.9.0
2023-04-05 09:48:23,735:INFO:PyCaret optional dependencies:
2023-04-05 09:48:23,735:INFO:                shap: 0.41.0
2023-04-05 09:48:23,735:INFO:           interpret: 0.3.2
2023-04-05 09:48:23,735:INFO:                umap: Not installed
2023-04-05 09:48:23,735:INFO:    pandas_profiling: Not installed
2023-04-05 09:48:23,735:INFO:  explainerdashboard: Not installed
2023-04-05 09:48:23,735:INFO:             autoviz: Not installed
2023-04-05 09:48:23,735:INFO:           fairlearn: Not installed
2023-04-05 09:48:23,735:INFO:             xgboost: 1.7.4
2023-04-05 09:48:23,735:INFO:            catboost: Not installed
2023-04-05 09:48:23,735:INFO:              kmodes: Not installed
2023-04-05 09:48:23,735:INFO:             mlxtend: Not installed
2023-04-05 09:48:23,735:INFO:       statsforecast: Not installed
2023-04-05 09:48:23,735:INFO:        tune_sklearn: Not installed
2023-04-05 09:48:23,735:INFO:                 ray: Not installed
2023-04-05 09:48:23,735:INFO:            hyperopt: Not installed
2023-04-05 09:48:23,735:INFO:              optuna: Not installed
2023-04-05 09:48:23,736:INFO:               skopt: Not installed
2023-04-05 09:48:23,736:INFO:              mlflow: Not installed
2023-04-05 09:48:23,736:INFO:              gradio: Not installed
2023-04-05 09:48:23,736:INFO:             fastapi: Not installed
2023-04-05 09:48:23,736:INFO:             uvicorn: Not installed
2023-04-05 09:48:23,736:INFO:              m2cgen: Not installed
2023-04-05 09:48:23,736:INFO:           evidently: Not installed
2023-04-05 09:48:23,736:INFO:               fugue: Not installed
2023-04-05 09:48:23,736:INFO:           streamlit: Not installed
2023-04-05 09:48:23,736:INFO:             prophet: Not installed
2023-04-05 09:48:23,736:INFO:None
2023-04-05 09:48:23,736:INFO:Set up data.
2023-04-05 09:48:26,991:INFO:Set up train/test split.
2023-04-05 09:48:27,911:INFO:Set up index.
2023-04-05 09:48:27,952:INFO:Set up folding strategy.
2023-04-05 09:48:27,952:INFO:Assigning column types.
2023-04-05 09:48:28,624:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-05 09:48:28,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-05 09:48:28,698:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-05 09:48:28,755:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 09:48:28,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 09:48:28,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-05 09:48:28,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-05 09:48:28,993:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 09:48:28,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 09:48:28,997:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-05 09:48:29,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-05 09:48:29,078:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 09:48:29,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 09:48:29,128:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-05 09:48:29,157:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 09:48:29,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 09:48:29,160:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-05 09:48:29,264:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 09:48:29,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 09:48:29,337:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 09:48:29,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 09:48:29,372:INFO:Preparing preprocessing pipeline...
2023-04-05 09:48:29,472:INFO:Set up simple imputation.
2023-04-05 09:48:31,776:INFO:Finished creating preprocessing pipeline.
2023-04-05 09:48:31,865:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\dufwn\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['word0', 'word1', 'word2', 'word3',
                                             'word4', 'word5', 'word6', 'word7',
                                             'word8', 'word9', 'word10',
                                             'word11', 'word12', 'word13',
                                             'word14', 'word15', 'word16',
                                             'word17', 'word18', 'word19',
                                             'word20', 'word21', 'word22',
                                             'word2...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-04-05 09:48:31,866:INFO:Creating final display dataframe.
2023-04-05 09:48:36,673:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type        Multiclass
3           Original data shape      (7925, 8135)
4        Transformed data shape      (7925, 8135)
5   Transformed train set shape      (5547, 8135)
6    Transformed test set shape      (2378, 8135)
7              Numeric features              8134
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              854d
2023-04-05 09:48:36,815:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 09:48:36,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 09:48:36,897:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 09:48:36,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 09:48:36,904:INFO:setup() successfully completed in 13.17s...............
2023-04-05 09:48:42,313:INFO:Initializing compare_models()
2023-04-05 09:48:42,313:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-05 09:48:42,313:INFO:Checking exceptions
2023-04-05 09:48:42,755:INFO:Preparing display monitor
2023-04-05 09:48:42,795:INFO:Initializing Logistic Regression
2023-04-05 09:48:42,795:INFO:Total runtime is 0.0 minutes
2023-04-05 09:48:42,802:INFO:SubProcess create_model() called ==================================
2023-04-05 09:48:42,802:INFO:Initializing create_model()
2023-04-05 09:48:42,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:48:42,802:INFO:Checking exceptions
2023-04-05 09:48:42,802:INFO:Importing libraries
2023-04-05 09:48:42,802:INFO:Copying training dataset
2023-04-05 09:48:43,630:INFO:Defining folds
2023-04-05 09:48:43,630:INFO:Declaring metric variables
2023-04-05 09:48:43,634:INFO:Importing untrained model
2023-04-05 09:48:43,639:INFO:Logistic Regression Imported successfully
2023-04-05 09:48:43,646:INFO:Starting cross validation
2023-04-05 09:48:43,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:48:53,307:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-05 09:48:53,348:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-05 09:48:56,907:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-05 09:48:57,007:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-05 09:48:58,096:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-05 09:49:56,400:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:49:58,430:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-05 09:49:58,953:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:49:59,563:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:00,243:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:50:00,629:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-05 09:50:01,323:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-05 09:50:01,603:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:50:01,729:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:02,275:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:02,548:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:03,491:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:03,519:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:05,484:INFO:Calculating mean and std
2023-04-05 09:50:05,486:INFO:Creating metrics dataframe
2023-04-05 09:50:05,525:INFO:Uploading results into container
2023-04-05 09:50:05,528:INFO:Uploading model into container now
2023-04-05 09:50:05,531:INFO:_master_model_container: 1
2023-04-05 09:50:05,531:INFO:_display_container: 2
2023-04-05 09:50:05,532:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-05 09:50:05,532:INFO:create_model() successfully completed......................................
2023-04-05 09:50:05,920:INFO:SubProcess create_model() end ==================================
2023-04-05 09:50:05,920:INFO:Creating metrics dataframe
2023-04-05 09:50:05,934:INFO:Initializing K Neighbors Classifier
2023-04-05 09:50:05,935:INFO:Total runtime is 1.3856590072313943 minutes
2023-04-05 09:50:05,941:INFO:SubProcess create_model() called ==================================
2023-04-05 09:50:05,942:INFO:Initializing create_model()
2023-04-05 09:50:05,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:50:05,943:INFO:Checking exceptions
2023-04-05 09:50:05,943:INFO:Importing libraries
2023-04-05 09:50:05,943:INFO:Copying training dataset
2023-04-05 09:50:06,618:INFO:Defining folds
2023-04-05 09:50:06,619:INFO:Declaring metric variables
2023-04-05 09:50:06,626:INFO:Importing untrained model
2023-04-05 09:50:06,631:INFO:K Neighbors Classifier Imported successfully
2023-04-05 09:50:06,638:INFO:Starting cross validation
2023-04-05 09:50:06,664:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:50:11,209:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:11,451:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:11,460:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:11,470:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:11,479:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:11,500:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:11,593:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:11,608:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:16,949:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:16,964:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:35,996:INFO:Calculating mean and std
2023-04-05 09:50:35,999:INFO:Creating metrics dataframe
2023-04-05 09:50:36,057:INFO:Uploading results into container
2023-04-05 09:50:36,058:INFO:Uploading model into container now
2023-04-05 09:50:36,058:INFO:_master_model_container: 2
2023-04-05 09:50:36,059:INFO:_display_container: 2
2023-04-05 09:50:36,059:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-05 09:50:36,059:INFO:create_model() successfully completed......................................
2023-04-05 09:50:36,371:INFO:SubProcess create_model() end ==================================
2023-04-05 09:50:36,371:INFO:Creating metrics dataframe
2023-04-05 09:50:36,413:INFO:Initializing Naive Bayes
2023-04-05 09:50:36,413:INFO:Total runtime is 1.8936228990554809 minutes
2023-04-05 09:50:36,418:INFO:SubProcess create_model() called ==================================
2023-04-05 09:50:36,419:INFO:Initializing create_model()
2023-04-05 09:50:36,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:50:36,419:INFO:Checking exceptions
2023-04-05 09:50:36,419:INFO:Importing libraries
2023-04-05 09:50:36,419:INFO:Copying training dataset
2023-04-05 09:50:37,025:INFO:Defining folds
2023-04-05 09:50:37,025:INFO:Declaring metric variables
2023-04-05 09:50:37,032:INFO:Importing untrained model
2023-04-05 09:50:37,037:INFO:Naive Bayes Imported successfully
2023-04-05 09:50:37,046:INFO:Starting cross validation
2023-04-05 09:50:37,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:50:42,177:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:50:43,352:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:43,521:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:43,565:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:43,612:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:43,854:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:46,513:INFO:Calculating mean and std
2023-04-05 09:50:46,515:INFO:Creating metrics dataframe
2023-04-05 09:50:46,551:INFO:Uploading results into container
2023-04-05 09:50:46,552:INFO:Uploading model into container now
2023-04-05 09:50:46,552:INFO:_master_model_container: 3
2023-04-05 09:50:46,552:INFO:_display_container: 2
2023-04-05 09:50:46,553:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-05 09:50:46,553:INFO:create_model() successfully completed......................................
2023-04-05 09:50:46,863:INFO:SubProcess create_model() end ==================================
2023-04-05 09:50:46,863:INFO:Creating metrics dataframe
2023-04-05 09:50:46,874:INFO:Initializing Decision Tree Classifier
2023-04-05 09:50:46,875:INFO:Total runtime is 2.0679903705914815 minutes
2023-04-05 09:50:46,878:INFO:SubProcess create_model() called ==================================
2023-04-05 09:50:46,879:INFO:Initializing create_model()
2023-04-05 09:50:46,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:50:46,879:INFO:Checking exceptions
2023-04-05 09:50:46,879:INFO:Importing libraries
2023-04-05 09:50:46,879:INFO:Copying training dataset
2023-04-05 09:50:47,556:INFO:Defining folds
2023-04-05 09:50:47,556:INFO:Declaring metric variables
2023-04-05 09:50:47,562:INFO:Importing untrained model
2023-04-05 09:50:47,567:INFO:Decision Tree Classifier Imported successfully
2023-04-05 09:50:47,575:INFO:Starting cross validation
2023-04-05 09:50:47,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:50:59,278:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:59,423:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:59,472:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:59,661:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:59,670:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:59,945:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:50:59,977:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:00,108:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:00,140:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:00,635:INFO:Calculating mean and std
2023-04-05 09:51:00,637:INFO:Creating metrics dataframe
2023-04-05 09:51:00,692:INFO:Uploading results into container
2023-04-05 09:51:00,692:INFO:Uploading model into container now
2023-04-05 09:51:00,693:INFO:_master_model_container: 4
2023-04-05 09:51:00,693:INFO:_display_container: 2
2023-04-05 09:51:00,693:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-04-05 09:51:00,693:INFO:create_model() successfully completed......................................
2023-04-05 09:51:00,978:INFO:SubProcess create_model() end ==================================
2023-04-05 09:51:00,979:INFO:Creating metrics dataframe
2023-04-05 09:51:00,991:INFO:Initializing SVM - Linear Kernel
2023-04-05 09:51:00,992:INFO:Total runtime is 2.3032821655273437 minutes
2023-04-05 09:51:00,999:INFO:SubProcess create_model() called ==================================
2023-04-05 09:51:00,999:INFO:Initializing create_model()
2023-04-05 09:51:01,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:51:01,000:INFO:Checking exceptions
2023-04-05 09:51:01,000:INFO:Importing libraries
2023-04-05 09:51:01,000:INFO:Copying training dataset
2023-04-05 09:51:01,575:INFO:Defining folds
2023-04-05 09:51:01,575:INFO:Declaring metric variables
2023-04-05 09:51:01,583:INFO:Importing untrained model
2023-04-05 09:51:01,589:INFO:SVM - Linear Kernel Imported successfully
2023-04-05 09:51:01,598:INFO:Starting cross validation
2023-04-05 09:51:01,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:51:20,953:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:51:22,484:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:22,765:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:23,403:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:23,419:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:23,580:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:23,599:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:23,847:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:23,986:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:24,166:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:24,311:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:24,366:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:24,512:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:24,517:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:24,556:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:51:24,646:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:24,646:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:24,674:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:24,840:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 09:51:25,102:INFO:Calculating mean and std
2023-04-05 09:51:25,105:INFO:Creating metrics dataframe
2023-04-05 09:51:25,187:INFO:Uploading results into container
2023-04-05 09:51:25,189:INFO:Uploading model into container now
2023-04-05 09:51:25,190:INFO:_master_model_container: 5
2023-04-05 09:51:25,190:INFO:_display_container: 2
2023-04-05 09:51:25,191:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-05 09:51:25,191:INFO:create_model() successfully completed......................................
2023-04-05 09:51:25,520:INFO:SubProcess create_model() end ==================================
2023-04-05 09:51:25,521:INFO:Creating metrics dataframe
2023-04-05 09:51:25,538:INFO:Initializing Ridge Classifier
2023-04-05 09:51:25,538:INFO:Total runtime is 2.712376324335734 minutes
2023-04-05 09:51:25,545:INFO:SubProcess create_model() called ==================================
2023-04-05 09:51:25,546:INFO:Initializing create_model()
2023-04-05 09:51:25,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:51:25,547:INFO:Checking exceptions
2023-04-05 09:51:25,547:INFO:Importing libraries
2023-04-05 09:51:25,547:INFO:Copying training dataset
2023-04-05 09:51:26,396:INFO:Defining folds
2023-04-05 09:51:26,397:INFO:Declaring metric variables
2023-04-05 09:51:26,402:INFO:Importing untrained model
2023-04-05 09:51:26,406:INFO:Ridge Classifier Imported successfully
2023-04-05 09:51:26,414:INFO:Starting cross validation
2023-04-05 09:51:26,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:51:40,141:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,733:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,800:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,847:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,857:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,876:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,883:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,897:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,936:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:40,937:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 09:51:41,274:INFO:Calculating mean and std
2023-04-05 09:51:41,275:INFO:Creating metrics dataframe
2023-04-05 09:51:41,312:INFO:Uploading results into container
2023-04-05 09:51:41,313:INFO:Uploading model into container now
2023-04-05 09:51:41,313:INFO:_master_model_container: 6
2023-04-05 09:51:41,313:INFO:_display_container: 2
2023-04-05 09:51:41,313:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-04-05 09:51:41,313:INFO:create_model() successfully completed......................................
2023-04-05 09:51:41,606:INFO:SubProcess create_model() end ==================================
2023-04-05 09:51:41,606:INFO:Creating metrics dataframe
2023-04-05 09:51:41,614:INFO:Initializing Random Forest Classifier
2023-04-05 09:51:41,614:INFO:Total runtime is 2.9803073008855185 minutes
2023-04-05 09:51:41,618:INFO:SubProcess create_model() called ==================================
2023-04-05 09:51:41,618:INFO:Initializing create_model()
2023-04-05 09:51:41,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:51:41,618:INFO:Checking exceptions
2023-04-05 09:51:41,619:INFO:Importing libraries
2023-04-05 09:51:41,619:INFO:Copying training dataset
2023-04-05 09:51:42,111:INFO:Defining folds
2023-04-05 09:51:42,112:INFO:Declaring metric variables
2023-04-05 09:51:42,116:INFO:Importing untrained model
2023-04-05 09:51:42,120:INFO:Random Forest Classifier Imported successfully
2023-04-05 09:51:42,125:INFO:Starting cross validation
2023-04-05 09:51:42,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:52:32,746:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:52:35,338:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:52:37,333:INFO:Calculating mean and std
2023-04-05 09:52:37,334:INFO:Creating metrics dataframe
2023-04-05 09:52:37,373:INFO:Uploading results into container
2023-04-05 09:52:37,374:INFO:Uploading model into container now
2023-04-05 09:52:37,375:INFO:_master_model_container: 7
2023-04-05 09:52:37,375:INFO:_display_container: 2
2023-04-05 09:52:37,375:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-04-05 09:52:37,375:INFO:create_model() successfully completed......................................
2023-04-05 09:52:37,608:INFO:SubProcess create_model() end ==================================
2023-04-05 09:52:37,608:INFO:Creating metrics dataframe
2023-04-05 09:52:37,617:INFO:Initializing Quadratic Discriminant Analysis
2023-04-05 09:52:37,618:INFO:Total runtime is 3.9137217362721763 minutes
2023-04-05 09:52:37,622:INFO:SubProcess create_model() called ==================================
2023-04-05 09:52:37,622:INFO:Initializing create_model()
2023-04-05 09:52:37,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:52:37,622:INFO:Checking exceptions
2023-04-05 09:52:37,622:INFO:Importing libraries
2023-04-05 09:52:37,622:INFO:Copying training dataset
2023-04-05 09:52:38,105:INFO:Defining folds
2023-04-05 09:52:38,105:INFO:Declaring metric variables
2023-04-05 09:52:38,108:INFO:Importing untrained model
2023-04-05 09:52:38,111:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-05 09:52:38,118:INFO:Starting cross validation
2023-04-05 09:52:38,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:53:41,469:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:53:41,760:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:53:41,836:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:53:41,906:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:53:41,951:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:53:41,967:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:53:42,078:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:53:42,132:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:53:42,305:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-05 09:57:29,786:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:57:30,535:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:57:30,898:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:57:31,685:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:57:32,091:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:57:32,250:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:57:32,253:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:32,322:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:57:32,506:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:32,830:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:32,908:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 09:57:33,369:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:33,711:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:34,061:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:34,171:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:34,304:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:34,873:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 09:57:38,118:INFO:Calculating mean and std
2023-04-05 09:57:38,119:INFO:Creating metrics dataframe
2023-04-05 09:57:38,163:INFO:Uploading results into container
2023-04-05 09:57:38,164:INFO:Uploading model into container now
2023-04-05 09:57:38,164:INFO:_master_model_container: 8
2023-04-05 09:57:38,164:INFO:_display_container: 2
2023-04-05 09:57:38,165:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-05 09:57:38,165:INFO:create_model() successfully completed......................................
2023-04-05 09:57:38,413:INFO:SubProcess create_model() end ==================================
2023-04-05 09:57:38,414:INFO:Creating metrics dataframe
2023-04-05 09:57:38,423:INFO:Initializing Ada Boost Classifier
2023-04-05 09:57:38,424:INFO:Total runtime is 8.927144873142243 minutes
2023-04-05 09:57:38,426:INFO:SubProcess create_model() called ==================================
2023-04-05 09:57:38,427:INFO:Initializing create_model()
2023-04-05 09:57:38,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:57:38,427:INFO:Checking exceptions
2023-04-05 09:57:38,427:INFO:Importing libraries
2023-04-05 09:57:38,427:INFO:Copying training dataset
2023-04-05 09:57:39,205:INFO:Defining folds
2023-04-05 09:57:39,206:INFO:Declaring metric variables
2023-04-05 09:57:39,210:INFO:Importing untrained model
2023-04-05 09:57:39,214:INFO:Ada Boost Classifier Imported successfully
2023-04-05 09:57:39,224:INFO:Starting cross validation
2023-04-05 09:57:39,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 09:57:59,363:INFO:Calculating mean and std
2023-04-05 09:57:59,364:INFO:Creating metrics dataframe
2023-04-05 09:57:59,412:INFO:Uploading results into container
2023-04-05 09:57:59,412:INFO:Uploading model into container now
2023-04-05 09:57:59,413:INFO:_master_model_container: 9
2023-04-05 09:57:59,413:INFO:_display_container: 2
2023-04-05 09:57:59,414:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-04-05 09:57:59,414:INFO:create_model() successfully completed......................................
2023-04-05 09:57:59,678:INFO:SubProcess create_model() end ==================================
2023-04-05 09:57:59,678:INFO:Creating metrics dataframe
2023-04-05 09:57:59,689:INFO:Initializing Gradient Boosting Classifier
2023-04-05 09:57:59,689:INFO:Total runtime is 9.281557234128316 minutes
2023-04-05 09:57:59,691:INFO:SubProcess create_model() called ==================================
2023-04-05 09:57:59,691:INFO:Initializing create_model()
2023-04-05 09:57:59,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A28055EB0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A214C9A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 09:57:59,692:INFO:Checking exceptions
2023-04-05 09:57:59,692:INFO:Importing libraries
2023-04-05 09:57:59,692:INFO:Copying training dataset
2023-04-05 09:58:00,363:INFO:Defining folds
2023-04-05 09:58:00,363:INFO:Declaring metric variables
2023-04-05 09:58:00,367:INFO:Importing untrained model
2023-04-05 09:58:00,370:INFO:Gradient Boosting Classifier Imported successfully
2023-04-05 09:58:00,377:INFO:Starting cross validation
2023-04-05 09:58:00,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 10:10:33,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-05 10:10:33,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-05 10:10:33,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-05 10:10:33,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-05 10:10:34,117:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-05 10:10:34,309:INFO:PyCaret ClassificationExperiment
2023-04-05 10:10:34,309:INFO:Logging name: clf-default-name
2023-04-05 10:10:34,309:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-05 10:10:34,310:INFO:version 3.0.0
2023-04-05 10:10:34,310:INFO:Initializing setup()
2023-04-05 10:10:34,310:INFO:self.USI: d376
2023-04-05 10:10:34,310:INFO:self._variable_keys: {'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_train', 'log_plots_param', 'gpu_param', '_available_plots', 'logging_param', 'fold_generator', 'y', 'exp_name_log', 'X_test', 'memory', '_ml_usecase', 'X_train', 'data', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'USI', 'is_multiclass', 'exp_id', 'target_param', 'X', 'fold_groups_param', 'n_jobs_param', 'y_test'}
2023-04-05 10:10:34,310:INFO:Checking environment
2023-04-05 10:10:34,310:INFO:python_version: 3.9.16
2023-04-05 10:10:34,310:INFO:python_build: ('main', 'Jan 11 2023 16:16:36')
2023-04-05 10:10:34,310:INFO:machine: AMD64
2023-04-05 10:10:34,310:INFO:platform: Windows-10-10.0.19045-SP0
2023-04-05 10:10:34,310:INFO:Memory: svmem(total=17007173632, available=8083439616, percent=52.5, used=8923734016, free=8083439616)
2023-04-05 10:10:34,310:INFO:Physical Core: 6
2023-04-05 10:10:34,310:INFO:Logical Core: 12
2023-04-05 10:10:34,310:INFO:Checking libraries
2023-04-05 10:10:34,310:INFO:System:
2023-04-05 10:10:34,310:INFO:    python: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]
2023-04-05 10:10:34,310:INFO:executable: c:\Users\dufwn\anaconda3\envs\tf26\python.exe
2023-04-05 10:10:34,310:INFO:   machine: Windows-10-10.0.19045-SP0
2023-04-05 10:10:34,310:INFO:PyCaret required dependencies:
2023-04-05 10:10:34,310:INFO:                 pip: 22.3.1
2023-04-05 10:10:34,310:INFO:          setuptools: 60.10.0
2023-04-05 10:10:34,310:INFO:             pycaret: 3.0.0
2023-04-05 10:10:34,310:INFO:             IPython: 8.10.0
2023-04-05 10:10:34,310:INFO:          ipywidgets: 8.0.6
2023-04-05 10:10:34,310:INFO:                tqdm: 4.64.1
2023-04-05 10:10:34,310:INFO:               numpy: 1.23.5
2023-04-05 10:10:34,310:INFO:              pandas: 1.5.3
2023-04-05 10:10:34,310:INFO:              jinja2: 3.1.2
2023-04-05 10:10:34,310:INFO:               scipy: 1.9.1
2023-04-05 10:10:34,310:INFO:              joblib: 1.2.0
2023-04-05 10:10:34,310:INFO:             sklearn: 1.2.2
2023-04-05 10:10:34,310:INFO:                pyod: 1.0.9
2023-04-05 10:10:34,310:INFO:            imblearn: 0.10.1
2023-04-05 10:10:34,311:INFO:   category_encoders: 2.6.0
2023-04-05 10:10:34,311:INFO:            lightgbm: 3.3.5
2023-04-05 10:10:34,311:INFO:               numba: 0.56.4
2023-04-05 10:10:34,311:INFO:            requests: 2.28.1
2023-04-05 10:10:34,311:INFO:          matplotlib: 3.7.1
2023-04-05 10:10:34,311:INFO:          scikitplot: 0.3.7
2023-04-05 10:10:34,311:INFO:         yellowbrick: 1.5
2023-04-05 10:10:34,311:INFO:              plotly: 5.14.0
2023-04-05 10:10:34,311:INFO:             kaleido: 0.2.1
2023-04-05 10:10:34,311:INFO:         statsmodels: 0.13.5
2023-04-05 10:10:34,311:INFO:              sktime: 0.17.0
2023-04-05 10:10:34,311:INFO:               tbats: 1.1.2
2023-04-05 10:10:34,311:INFO:            pmdarima: 2.0.3
2023-04-05 10:10:34,311:INFO:              psutil: 5.9.0
2023-04-05 10:10:34,311:INFO:PyCaret optional dependencies:
2023-04-05 10:10:34,319:INFO:                shap: 0.41.0
2023-04-05 10:10:34,319:INFO:           interpret: 0.3.2
2023-04-05 10:10:34,319:INFO:                umap: Not installed
2023-04-05 10:10:34,319:INFO:    pandas_profiling: Not installed
2023-04-05 10:10:34,319:INFO:  explainerdashboard: Not installed
2023-04-05 10:10:34,319:INFO:             autoviz: Not installed
2023-04-05 10:10:34,319:INFO:           fairlearn: Not installed
2023-04-05 10:10:34,319:INFO:             xgboost: 1.7.4
2023-04-05 10:10:34,319:INFO:            catboost: Not installed
2023-04-05 10:10:34,319:INFO:              kmodes: Not installed
2023-04-05 10:10:34,319:INFO:             mlxtend: Not installed
2023-04-05 10:10:34,319:INFO:       statsforecast: Not installed
2023-04-05 10:10:34,319:INFO:        tune_sklearn: Not installed
2023-04-05 10:10:34,319:INFO:                 ray: Not installed
2023-04-05 10:10:34,319:INFO:            hyperopt: Not installed
2023-04-05 10:10:34,319:INFO:              optuna: Not installed
2023-04-05 10:10:34,319:INFO:               skopt: Not installed
2023-04-05 10:10:34,319:INFO:              mlflow: Not installed
2023-04-05 10:10:34,319:INFO:              gradio: Not installed
2023-04-05 10:10:34,319:INFO:             fastapi: Not installed
2023-04-05 10:10:34,319:INFO:             uvicorn: Not installed
2023-04-05 10:10:34,319:INFO:              m2cgen: Not installed
2023-04-05 10:10:34,319:INFO:           evidently: Not installed
2023-04-05 10:10:34,319:INFO:               fugue: Not installed
2023-04-05 10:10:34,320:INFO:           streamlit: Not installed
2023-04-05 10:10:34,320:INFO:             prophet: Not installed
2023-04-05 10:10:34,320:INFO:None
2023-04-05 10:10:34,320:INFO:Set up data.
2023-04-05 10:10:36,069:INFO:Set up train/test split.
2023-04-05 10:10:36,427:INFO:Set up index.
2023-04-05 10:10:36,445:INFO:Set up folding strategy.
2023-04-05 10:10:36,445:INFO:Assigning column types.
2023-04-05 10:10:36,783:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-05 10:10:36,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-05 10:10:36,821:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-05 10:10:36,850:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 10:10:36,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 10:10:36,927:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-05 10:10:36,927:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-05 10:10:36,949:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 10:10:36,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 10:10:36,951:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-05 10:10:36,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-05 10:10:37,006:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 10:10:37,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 10:10:37,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-05 10:10:37,064:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 10:10:37,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 10:10:37,067:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-05 10:10:37,126:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 10:10:37,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 10:10:37,184:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 10:10:37,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 10:10:37,187:INFO:Preparing preprocessing pipeline...
2023-04-05 10:10:37,230:INFO:Set up simple imputation.
2023-04-05 10:10:38,260:INFO:Finished creating preprocessing pipeline.
2023-04-05 10:10:38,295:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\dufwn\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['word0', 'word1', 'word2', 'word3',
                                             'word4', 'word5', 'word6', 'word7',
                                             'word8', 'word9', 'word10',
                                             'word11', 'word12', 'word13',
                                             'word14', 'word15', 'word16',
                                             'word17', 'word18', 'word19',
                                             'word20', 'word21', 'word22',
                                             'word2...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-04-05 10:10:38,295:INFO:Creating final display dataframe.
2023-04-05 10:10:40,635:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             label
2                   Target type        Multiclass
3           Original data shape      (3706, 8135)
4        Transformed data shape      (3706, 8135)
5   Transformed train set shape      (2594, 8135)
6    Transformed test set shape      (1112, 8135)
7              Numeric features              8134
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d376
2023-04-05 10:10:40,700:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 10:10:40,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 10:10:40,759:INFO:Soft dependency imported: xgboost: 1.7.4
2023-04-05 10:10:40,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-05 10:10:40,763:INFO:setup() successfully completed in 6.51s...............
2023-04-05 10:10:44,557:INFO:Initializing compare_models()
2023-04-05 10:10:44,557:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-05 10:10:44,558:INFO:Checking exceptions
2023-04-05 10:10:44,773:INFO:Preparing display monitor
2023-04-05 10:10:44,791:INFO:Initializing Logistic Regression
2023-04-05 10:10:44,791:INFO:Total runtime is 1.662572224934896e-05 minutes
2023-04-05 10:10:44,794:INFO:SubProcess create_model() called ==================================
2023-04-05 10:10:44,794:INFO:Initializing create_model()
2023-04-05 10:10:44,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C3BA712E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 10:10:44,794:INFO:Checking exceptions
2023-04-05 10:10:44,794:INFO:Importing libraries
2023-04-05 10:10:44,795:INFO:Copying training dataset
2023-04-05 10:10:45,131:INFO:Defining folds
2023-04-05 10:10:45,132:INFO:Declaring metric variables
2023-04-05 10:10:45,135:INFO:Importing untrained model
2023-04-05 10:10:45,137:INFO:Logistic Regression Imported successfully
2023-04-05 10:10:45,144:INFO:Starting cross validation
2023-04-05 10:10:45,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 10:11:18,771:INFO:Calculating mean and std
2023-04-05 10:11:18,772:INFO:Creating metrics dataframe
2023-04-05 10:11:18,831:INFO:Uploading results into container
2023-04-05 10:11:18,832:INFO:Uploading model into container now
2023-04-05 10:11:18,834:INFO:_master_model_container: 1
2023-04-05 10:11:18,834:INFO:_display_container: 2
2023-04-05 10:11:18,834:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-05 10:11:18,834:INFO:create_model() successfully completed......................................
2023-04-05 10:11:19,000:INFO:SubProcess create_model() end ==================================
2023-04-05 10:11:19,000:INFO:Creating metrics dataframe
2023-04-05 10:11:19,006:INFO:Initializing K Neighbors Classifier
2023-04-05 10:11:19,006:INFO:Total runtime is 0.5702586730321249 minutes
2023-04-05 10:11:19,008:INFO:SubProcess create_model() called ==================================
2023-04-05 10:11:19,009:INFO:Initializing create_model()
2023-04-05 10:11:19,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C3BA712E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 10:11:19,009:INFO:Checking exceptions
2023-04-05 10:11:19,009:INFO:Importing libraries
2023-04-05 10:11:19,009:INFO:Copying training dataset
2023-04-05 10:11:19,278:INFO:Defining folds
2023-04-05 10:11:19,278:INFO:Declaring metric variables
2023-04-05 10:11:19,282:INFO:Importing untrained model
2023-04-05 10:11:19,285:INFO:K Neighbors Classifier Imported successfully
2023-04-05 10:11:19,290:INFO:Starting cross validation
2023-04-05 10:11:19,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 10:11:27,714:INFO:Calculating mean and std
2023-04-05 10:11:27,714:INFO:Creating metrics dataframe
2023-04-05 10:11:27,772:INFO:Uploading results into container
2023-04-05 10:11:27,772:INFO:Uploading model into container now
2023-04-05 10:11:27,772:INFO:_master_model_container: 2
2023-04-05 10:11:27,772:INFO:_display_container: 2
2023-04-05 10:11:27,773:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-05 10:11:27,773:INFO:create_model() successfully completed......................................
2023-04-05 10:11:27,932:INFO:SubProcess create_model() end ==================================
2023-04-05 10:11:27,932:INFO:Creating metrics dataframe
2023-04-05 10:11:27,939:INFO:Initializing Naive Bayes
2023-04-05 10:11:27,939:INFO:Total runtime is 0.7191405057907104 minutes
2023-04-05 10:11:27,942:INFO:SubProcess create_model() called ==================================
2023-04-05 10:11:27,942:INFO:Initializing create_model()
2023-04-05 10:11:27,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C3BA712E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 10:11:27,942:INFO:Checking exceptions
2023-04-05 10:11:27,942:INFO:Importing libraries
2023-04-05 10:11:27,942:INFO:Copying training dataset
2023-04-05 10:11:28,211:INFO:Defining folds
2023-04-05 10:11:28,211:INFO:Declaring metric variables
2023-04-05 10:11:28,213:INFO:Importing untrained model
2023-04-05 10:11:28,216:INFO:Naive Bayes Imported successfully
2023-04-05 10:11:28,220:INFO:Starting cross validation
2023-04-05 10:11:28,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 10:11:32,792:INFO:Calculating mean and std
2023-04-05 10:11:32,793:INFO:Creating metrics dataframe
2023-04-05 10:11:32,858:INFO:Uploading results into container
2023-04-05 10:11:32,859:INFO:Uploading model into container now
2023-04-05 10:11:32,859:INFO:_master_model_container: 3
2023-04-05 10:11:32,859:INFO:_display_container: 2
2023-04-05 10:11:32,859:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-05 10:11:32,859:INFO:create_model() successfully completed......................................
2023-04-05 10:11:33,009:INFO:SubProcess create_model() end ==================================
2023-04-05 10:11:33,009:INFO:Creating metrics dataframe
2023-04-05 10:11:33,015:INFO:Initializing Decision Tree Classifier
2023-04-05 10:11:33,015:INFO:Total runtime is 0.8037470539410909 minutes
2023-04-05 10:11:33,017:INFO:SubProcess create_model() called ==================================
2023-04-05 10:11:33,018:INFO:Initializing create_model()
2023-04-05 10:11:33,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C3BA712E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 10:11:33,018:INFO:Checking exceptions
2023-04-05 10:11:33,018:INFO:Importing libraries
2023-04-05 10:11:33,018:INFO:Copying training dataset
2023-04-05 10:11:33,281:INFO:Defining folds
2023-04-05 10:11:33,281:INFO:Declaring metric variables
2023-04-05 10:11:33,284:INFO:Importing untrained model
2023-04-05 10:11:33,288:INFO:Decision Tree Classifier Imported successfully
2023-04-05 10:11:33,295:INFO:Starting cross validation
2023-04-05 10:11:33,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 10:11:39,082:INFO:Calculating mean and std
2023-04-05 10:11:39,082:INFO:Creating metrics dataframe
2023-04-05 10:11:39,151:INFO:Uploading results into container
2023-04-05 10:11:39,151:INFO:Uploading model into container now
2023-04-05 10:11:39,151:INFO:_master_model_container: 4
2023-04-05 10:11:39,151:INFO:_display_container: 2
2023-04-05 10:11:39,152:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-04-05 10:11:39,152:INFO:create_model() successfully completed......................................
2023-04-05 10:11:39,309:INFO:SubProcess create_model() end ==================================
2023-04-05 10:11:39,309:INFO:Creating metrics dataframe
2023-04-05 10:11:39,316:INFO:Initializing SVM - Linear Kernel
2023-04-05 10:11:39,316:INFO:Total runtime is 0.9087671756744384 minutes
2023-04-05 10:11:39,318:INFO:SubProcess create_model() called ==================================
2023-04-05 10:11:39,319:INFO:Initializing create_model()
2023-04-05 10:11:39,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C3BA712E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 10:11:39,319:INFO:Checking exceptions
2023-04-05 10:11:39,319:INFO:Importing libraries
2023-04-05 10:11:39,319:INFO:Copying training dataset
2023-04-05 10:11:39,594:INFO:Defining folds
2023-04-05 10:11:39,595:INFO:Declaring metric variables
2023-04-05 10:11:39,598:INFO:Importing untrained model
2023-04-05 10:11:39,601:INFO:SVM - Linear Kernel Imported successfully
2023-04-05 10:11:39,605:INFO:Starting cross validation
2023-04-05 10:11:39,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 10:11:50,873:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:51,663:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:51,830:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:52,016:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:52,027:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:52,056:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:52,105:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:52,112:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:52,169:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:52,297:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-05 10:11:52,688:INFO:Calculating mean and std
2023-04-05 10:11:52,689:INFO:Creating metrics dataframe
2023-04-05 10:11:52,760:INFO:Uploading results into container
2023-04-05 10:11:52,761:INFO:Uploading model into container now
2023-04-05 10:11:52,761:INFO:_master_model_container: 5
2023-04-05 10:11:52,761:INFO:_display_container: 2
2023-04-05 10:11:52,762:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-05 10:11:52,762:INFO:create_model() successfully completed......................................
2023-04-05 10:11:52,911:INFO:SubProcess create_model() end ==================================
2023-04-05 10:11:52,911:INFO:Creating metrics dataframe
2023-04-05 10:11:52,919:INFO:Initializing Ridge Classifier
2023-04-05 10:11:52,919:INFO:Total runtime is 1.135471475124359 minutes
2023-04-05 10:11:52,922:INFO:SubProcess create_model() called ==================================
2023-04-05 10:11:52,922:INFO:Initializing create_model()
2023-04-05 10:11:52,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C3BA712E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 10:11:52,922:INFO:Checking exceptions
2023-04-05 10:11:52,922:INFO:Importing libraries
2023-04-05 10:11:52,922:INFO:Copying training dataset
2023-04-05 10:11:53,177:INFO:Defining folds
2023-04-05 10:11:53,178:INFO:Declaring metric variables
2023-04-05 10:11:53,181:INFO:Importing untrained model
2023-04-05 10:11:53,184:INFO:Ridge Classifier Imported successfully
2023-04-05 10:11:53,189:INFO:Starting cross validation
2023-04-05 10:11:53,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 10:11:56,960:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,113:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,152:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,228:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,306:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,311:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,314:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,314:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,315:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,318:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-05 10:11:57,984:INFO:Calculating mean and std
2023-04-05 10:11:57,985:INFO:Creating metrics dataframe
2023-04-05 10:11:58,061:INFO:Uploading results into container
2023-04-05 10:11:58,062:INFO:Uploading model into container now
2023-04-05 10:11:58,062:INFO:_master_model_container: 6
2023-04-05 10:11:58,062:INFO:_display_container: 2
2023-04-05 10:11:58,062:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-04-05 10:11:58,063:INFO:create_model() successfully completed......................................
2023-04-05 10:11:58,204:INFO:SubProcess create_model() end ==================================
2023-04-05 10:11:58,204:INFO:Creating metrics dataframe
2023-04-05 10:11:58,211:INFO:Initializing Random Forest Classifier
2023-04-05 10:11:58,212:INFO:Total runtime is 1.2236881931622823 minutes
2023-04-05 10:11:58,214:INFO:SubProcess create_model() called ==================================
2023-04-05 10:11:58,214:INFO:Initializing create_model()
2023-04-05 10:11:58,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018C31267A60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C3BA712E0>, model_only=True, return_train_score=False, kwargs={})
2023-04-05 10:11:58,214:INFO:Checking exceptions
2023-04-05 10:11:58,214:INFO:Importing libraries
2023-04-05 10:11:58,215:INFO:Copying training dataset
2023-04-05 10:11:58,485:INFO:Defining folds
2023-04-05 10:11:58,485:INFO:Declaring metric variables
2023-04-05 10:11:58,488:INFO:Importing untrained model
2023-04-05 10:11:58,492:INFO:Random Forest Classifier Imported successfully
2023-04-05 10:11:58,497:INFO:Starting cross validation
2023-04-05 10:11:58,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-05 10:12:12,335:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 10:12:12,685:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-05 10:12:18,019:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-05 10:12:18,128:WARNING:c:\Users\dufwn\anaconda3\envs\tf26\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

